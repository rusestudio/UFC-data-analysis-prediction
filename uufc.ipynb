{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60dc05fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a7b9cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to get 10 page\n",
    "BASE_URL = \"http://ufcstats.com\"\n",
    "MATCH_URL = f\"{BASE_URL}/statistics/events/completed?page=\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b9c2266a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping event list page 1: http://ufcstats.com/statistics/events/completed?page=1\n",
      "Scraping event list page 2: http://ufcstats.com/statistics/events/completed?page=2\n",
      "Scraping event list page 3: http://ufcstats.com/statistics/events/completed?page=3\n",
      "Scraping event list page 4: http://ufcstats.com/statistics/events/completed?page=4\n",
      "Scraping event list page 5: http://ufcstats.com/statistics/events/completed?page=5\n",
      "Scraping event list page 6: http://ufcstats.com/statistics/events/completed?page=6\n",
      "Scraping event list page 7: http://ufcstats.com/statistics/events/completed?page=7\n",
      "Scraping event list page 8: http://ufcstats.com/statistics/events/completed?page=8\n",
      "Scraping event list page 9: http://ufcstats.com/statistics/events/completed?page=9\n",
      "Scraping event list page 10: http://ufcstats.com/statistics/events/completed?page=10\n",
      "Scraping event list page 11: http://ufcstats.com/statistics/events/completed?page=11\n",
      "Scraping event list page 12: http://ufcstats.com/statistics/events/completed?page=12\n",
      "Scraping event list page 13: http://ufcstats.com/statistics/events/completed?page=13\n",
      "Scraping event list page 14: http://ufcstats.com/statistics/events/completed?page=14\n",
      "Scraping event list page 15: http://ufcstats.com/statistics/events/completed?page=15\n",
      "Scraping event list page 16: http://ufcstats.com/statistics/events/completed?page=16\n",
      "Scraping event list page 17: http://ufcstats.com/statistics/events/completed?page=17\n",
      "Scraping event list page 18: http://ufcstats.com/statistics/events/completed?page=18\n",
      "Collected 449 match links.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['http://ufcstats.com/event-details/0e2c2daf11b5d8f2',\n",
       " 'http://ufcstats.com/event-details/7956f026e2672c47',\n",
       " 'http://ufcstats.com/event-details/38e5d9dcb0fddc42',\n",
       " 'http://ufcstats.com/event-details/9336e86cfd4ceaa1',\n",
       " 'http://ufcstats.com/event-details/8944a0f9b2f0ce6d']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match_links = [] #all match link in 10 page\n",
    "\n",
    "for page in range(1, 19):\n",
    "    url = f\"{MATCH_URL}{page}\" #get all url till page 10 and jan\n",
    "    print(f\"Scraping event list page {page}: {url}\") #print page link\n",
    "    \n",
    "    response = requests.get(url) #req again to every page\n",
    "\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\") #get html tag in all page\n",
    "    \n",
    "    rows = soup.find_all(\"tr\", class_=\"b-statistics__table-row\") # in html find links of match in each page\n",
    "    \n",
    "    for row in rows: # in every row\n",
    "        link_tag = row.find(\"a\") #find match links tag\n",
    "        date_tag = row.find(\"span\", class_=\"b-statistics__date\") #find date\n",
    "        \n",
    "        if link_tag and date_tag:\n",
    "            date_text = date_tag.text.strip()\n",
    "            if date_text == \"January 03, 2015\":\n",
    "                match_links.append(link_tag[\"href\"])\n",
    "                print(\"Reached Jan 03, 2015 — stopping.\") #stop at 2015\n",
    "                break\n",
    "            match_links.append(link_tag[\"href\"]) #save match link #all match link in 10 page. there are 245 match\n",
    "    else:\n",
    "        continue\n",
    "    break  # stop outer loop too once we reach Jan 03, 2015\n",
    "\n",
    "print(f\"Collected {len(match_links)} match links.\")\n",
    "match_links[:5] #print first 5 match links\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fb643cc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "filter category: 100%|██████████| 13/13 [00:00<00:00, 13078.90it/s]\n",
      "filter category: 100%|██████████| 13/13 [00:00<00:00, 13170.52it/s]\n",
      "filter category: 100%|██████████| 13/13 [00:00<00:00, 13028.90it/s]\n",
      "filter category: 100%|██████████| 12/12 [00:00<00:00, 11938.25it/s]\n",
      "filter category: 100%|██████████| 14/14 [00:00<00:00, 7043.33it/s]\n",
      "filter category: 100%|██████████| 12/12 [00:00<00:00, 5752.85it/s]\n",
      "filter category: 100%|██████████| 14/14 [00:00<00:00, 14004.35it/s]\n",
      "filter category: 100%|██████████| 13/13 [00:00<00:00, 12936.17it/s]\n",
      "filter category: 100%|██████████| 12/12 [00:00<00:00, 5977.63it/s]\n",
      "filter category: 100%|██████████| 12/12 [00:00<00:00, 5965.59it/s]\n",
      "filter category: 100%|██████████| 12/12 [00:00<00:00, 6019.81it/s]\n",
      "filter category: 100%|██████████| 12/12 [00:00<00:00, 828.45it/s]\n",
      "filter category: 100%|██████████| 12/12 [00:00<00:00, 736.21it/s]\n",
      "filter category: 100%|██████████| 14/14 [00:00<00:00, 2512.96it/s]\n",
      "filter category: 100%|██████████| 12/12 [00:00<00:00, 2644.86it/s]\n",
      "filter category: 100%|██████████| 11/11 [00:00<00:00, 2417.97it/s]\n",
      "filter category: 100%|██████████| 12/12 [00:00<00:00, 2163.31it/s]\n",
      "filter category: 100%|██████████| 13/13 [00:00<00:00, 4333.99it/s]\n",
      "filter category: 100%|██████████| 13/13 [00:00<00:00, 6462.72it/s]\n",
      "filter category: 100%|██████████| 9/9 [00:00<00:00, 8951.56it/s]\n",
      "filter category: 100%|██████████| 11/11 [00:00<00:00, 3669.85it/s]\n",
      "filter category: 100%|██████████| 12/12 [00:00<00:00, 3999.34it/s]\n",
      "filter category: 100%|██████████| 12/12 [00:00<00:00, 4000.29it/s]\n",
      "filter category: 100%|██████████| 14/14 [00:00<00:00, 3994.85it/s]\n",
      "filter category: 100%|██████████| 13/13 [00:00<00:00, 4335.72it/s]\n",
      "filter category: 100%|██████████| 12/12 [00:00<00:00, 3002.01it/s]\n",
      "filter category: 100%|██████████| 12/12 [00:00<00:00, 2644.30it/s]\n",
      "filter category: 100%|██████████| 13/13 [00:00<00:00, 4335.72it/s]\n",
      "filter category: 100%|██████████| 13/13 [00:00<00:00, 4137.02it/s]\n",
      "filter category: 100%|██████████| 10/10 [00:00<00:00, 3339.95it/s]\n",
      "filter category: 100%|██████████| 10/10 [00:00<00:00, 1667.12it/s]\n",
      "filter category: 100%|██████████| 12/12 [00:00<00:00, 3000.40it/s]\n",
      "filter category: 100%|██████████| 12/12 [00:00<00:00, 3990.46it/s]\n",
      "filter category: 100%|██████████| 12/12 [00:00<00:00, 1964.62it/s]\n",
      "filter category: 100%|██████████| 11/11 [00:00<00:00, 3650.97it/s]\n",
      "filter category: 100%|██████████| 13/13 [00:00<00:00, 5136.69it/s]\n",
      "filter category: 100%|██████████| 14/14 [00:00<00:00, 3484.05it/s]\n",
      "filter category: 100%|██████████| 13/13 [00:00<00:00, 3688.42it/s]\n",
      "filter category: 100%|██████████| 14/14 [00:00<00:00, 3970.80it/s]\n",
      "filter category: 100%|██████████| 13/13 [00:00<00:00, 4339.51it/s]\n",
      "filter category: 100%|██████████| 12/12 [00:00<00:00, 4980.87it/s]\n",
      "filter category: 100%|██████████| 11/11 [00:00<00:00, 4384.43it/s]\n",
      "filter category: 100%|██████████| 13/13 [00:00<00:00, 4344.01it/s]\n",
      "filter category: 100%|██████████| 13/13 [00:00<00:00, 4337.78it/s]\n",
      "filter category: 100%|██████████| 11/11 [00:00<00:00, 2175.88it/s]\n",
      "filter category: 100%|██████████| 12/12 [00:00<00:00, 3977.53it/s]\n",
      "filter category: 100%|██████████| 12/12 [00:00<00:00, 3394.82it/s]\n",
      "filter category: 100%|██████████| 14/14 [00:00<00:00, 4650.74it/s]\n",
      "filter category: 100%|██████████| 10/10 [00:00<00:00, 1989.42it/s]\n",
      "filter category: 100%|██████████| 12/12 [00:00<00:00, 3994.89it/s]\n",
      "filter category: 100%|██████████| 11/11 [00:00<00:00, 2435.07it/s]\n",
      "filter category: 100%|██████████| 12/12 [00:00<00:00, 4788.93it/s]\n",
      "filter category: 100%|██████████| 10/10 [00:00<00:00, 2481.25it/s]\n",
      "filter category: 100%|██████████| 13/13 [00:00<00:00, 4315.47it/s]\n",
      "filter category: 100%|██████████| 14/14 [00:00<00:00, 5530.26it/s]\n",
      "filter category: 100%|██████████| 11/11 [00:00<00:00, 5478.19it/s]\n",
      "filter category: 100%|██████████| 12/12 [00:00<00:00, 5921.37it/s]\n",
      "filter category: 100%|██████████| 13/13 [00:00<00:00, 4333.65it/s]\n",
      "filter category: 100%|██████████| 11/11 [00:00<00:00, 3651.84it/s]\n",
      "filter category: 100%|██████████| 11/11 [00:00<00:00, 7253.16it/s]\n",
      "filter category: 100%|██████████| 14/14 [00:00<00:00, 7004.68it/s]\n",
      "filter category: 100%|██████████| 12/12 [00:00<00:00, 3383.64it/s]\n",
      "filter category: 100%|██████████| 12/12 [00:00<00:00, 2647.22it/s]\n",
      "filter category: 100%|██████████| 12/12 [00:00<00:00, 2988.82it/s]\n",
      "filter category: 100%|██████████| 13/13 [00:00<00:00, 1608.62it/s]\n",
      "filter category: 100%|██████████| 13/13 [00:00<00:00, 5152.22it/s]\n",
      "filter category: 100%|██████████| 13/13 [00:00<00:00, 3242.12it/s]\n",
      "filter category: 100%|██████████| 12/12 [00:00<00:00, 3978.47it/s]\n",
      "filter category: 100%|██████████| 13/13 [00:00<00:00, 3250.24it/s]\n",
      "filter category: 100%|██████████| 13/13 [00:00<00:00, 3251.20it/s]\n",
      "filter category: 100%|██████████| 13/13 [00:00<00:00, 4338.47it/s]\n",
      "filter category: 100%|██████████| 14/14 [00:00<00:00, 5505.88it/s]\n",
      "filter category: 100%|██████████| 11/11 [00:00<00:00, 3625.15it/s]\n",
      "filter category: 100%|██████████| 12/12 [00:00<00:00, 4744.24it/s]\n",
      "filter category: 100%|██████████| 12/12 [00:00<00:00, 4027.82it/s]\n",
      "filter category: 100%|██████████| 14/14 [00:00<00:00, 5507.95it/s]\n",
      "filter category: 100%|██████████| 13/13 [00:00<00:00, 4310.35it/s]\n",
      "filter category: 100%|██████████| 12/12 [00:00<00:00, 2172.09it/s]\n",
      "filter category: 100%|██████████| 11/11 [00:00<00:00, 3683.91it/s]\n",
      "filter category: 100%|██████████| 12/12 [00:00<00:00, 6001.15it/s]\n",
      "filter category: 100%|██████████| 11/11 [00:00<00:00, 10990.32it/s]\n",
      "filter category: 100%|██████████| 12/12 [00:00<00:00, 6003.30it/s]\n",
      "filter category: 100%|██████████| 14/14 [00:00<00:00, 4686.37it/s]\n",
      "filter category: 100%|██████████| 13/13 [00:00<00:00, 4167.69it/s]\n",
      "filter category: 100%|██████████| 10/10 [00:00<00:00, 2384.89it/s]\n",
      "filter category: 100%|██████████| 13/13 [00:00<00:00, 4330.21it/s]\n",
      "filter category: 100%|██████████| 11/11 [00:00<00:00, 1464.35it/s]\n",
      "filter category: 100%|██████████| 10/10 [00:00<00:00, 3961.00it/s]\n",
      "filter category: 100%|██████████| 11/11 [00:00<00:00, 3630.29it/s]\n",
      "filter category: 100%|██████████| 11/11 [00:00<00:00, 5479.49it/s]\n",
      "filter category: 100%|██████████| 12/12 [00:00<00:00, 3983.83it/s]\n",
      "filter category: 100%|██████████| 11/11 [00:00<00:00, 5501.71it/s]\n",
      "filter category: 100%|██████████| 13/13 [00:00<00:00, 3687.67it/s]\n",
      "filter category: 100%|██████████| 12/12 [00:00<00:00, 3985.09it/s]\n",
      "filter category: 100%|██████████| 13/13 [00:00<00:00, 4327.46it/s]\n",
      "filter category: 100%|██████████| 12/12 [00:00<00:00, 3977.84it/s]\n",
      "filter category: 100%|██████████| 11/11 [00:00<00:00, 5546.69it/s]\n",
      "filter category: 100%|██████████| 15/15 [00:00<00:00, 2716.99it/s]\n",
      "filter category: 100%|██████████| 13/13 [00:00<00:00, 4336.06it/s]\n",
      "filter category: 100%|██████████| 13/13 [00:00<00:00, 3236.73it/s]\n",
      "filter category: 100%|██████████| 12/12 [00:00<00:00, 5993.29it/s]\n",
      "filter category: 100%|██████████| 13/13 [00:00<00:00, 5890.24it/s]\n",
      "filter category: 100%|██████████| 12/12 [00:00<00:00, 2637.24it/s]\n",
      "filter category: 100%|██████████| 11/11 [00:00<00:00, 5412.64it/s]\n",
      "filter category: 100%|██████████| 13/13 [00:00<00:00, 2863.76it/s]\n",
      "filter category: 100%|██████████| 12/12 [00:00<00:00, 3997.43it/s]\n",
      "filter category: 100%|██████████| 11/11 [00:00<00:00, 4346.02it/s]\n",
      "filter category: 100%|██████████| 12/12 [00:00<00:00, 4784.38it/s]\n",
      "filter category: 100%|██████████| 11/11 [00:00<00:00, 3112.97it/s]\n",
      "filter category: 100%|██████████| 11/11 [00:00<00:00, 5472.35it/s]\n",
      "filter category: 100%|██████████| 14/14 [00:00<00:00, 3086.64it/s]\n",
      "filter category: 100%|██████████| 12/12 [00:00<00:00, 3391.85it/s]\n",
      "filter category: 100%|██████████| 10/10 [00:00<00:00, 1521.44it/s]\n",
      "filter category: 100%|██████████| 15/15 [00:00<00:00, 5011.12it/s]\n",
      "filter category: 100%|██████████| 13/13 [00:00<00:00, 6512.12it/s]\n",
      "filter category: 100%|██████████| 14/14 [00:00<00:00, 3474.37it/s]\n",
      "filter category: 100%|██████████| 10/10 [00:00<00:00, 3334.10it/s]\n",
      "filter category: 100%|██████████| 11/11 [00:00<00:00, 3670.73it/s]\n",
      "filter category: 100%|██████████| 13/13 [00:00<00:00, 8611.17it/s]\n",
      "filter category: 100%|██████████| 11/11 [00:00<00:00, 3673.94it/s]\n",
      "filter category: 100%|██████████| 15/15 [00:00<00:00, 5944.31it/s]\n",
      "filter category: 100%|██████████| 11/11 [00:00<00:00, 5458.10it/s]\n",
      "filter category: 100%|██████████| 13/13 [00:00<00:00, 4257.51it/s]\n",
      "filter category: 100%|██████████| 12/12 [00:00<00:00, 2651.13it/s]\n",
      "filter category: 100%|██████████| 14/14 [00:00<00:00, 3500.25it/s]\n",
      "filter category: 100%|██████████| 11/11 [00:00<00:00, 3112.55it/s]\n",
      "filter category: 100%|██████████| 14/14 [00:00<00:00, 6928.64it/s]\n",
      "filter category: 100%|██████████| 11/11 [00:00<00:00, 5426.01it/s]\n",
      "filter category: 100%|██████████| 11/11 [00:00<00:00, 3649.53it/s]\n",
      "filter category: 100%|██████████| 12/12 [00:00<00:00, 3998.38it/s]\n",
      "filter category: 100%|██████████| 11/11 [00:00<00:00, 3650.40it/s]\n",
      "filter category: 100%|██████████| 11/11 [00:00<00:00, 3246.59it/s]\n",
      "filter category: 100%|██████████| 13/13 [00:00<00:00, 6176.48it/s]\n",
      "filter category: 100%|██████████| 13/13 [00:00<00:00, 3685.43it/s]\n",
      "filter category: 100%|██████████| 12/12 [00:00<00:00, 3981.62it/s]\n",
      "filter category: 100%|██████████| 12/12 [00:00<00:00, 2870.03it/s]\n",
      "filter category: 100%|██████████| 13/13 [00:00<00:00, 6502.02it/s]\n",
      "filter category: 100%|██████████| 10/10 [00:00<00:00, 5048.51it/s]\n",
      "filter category: 100%|██████████| 13/13 [00:00<00:00, 2871.30it/s]\n",
      "filter category: 100%|██████████| 14/14 [00:00<00:00, 2907.23it/s]\n",
      "filter category: 100%|██████████| 12/12 [00:00<00:00, 6016.21it/s]\n",
      "filter category: 100%|██████████| 11/11 [00:00<00:00, 2742.68it/s]\n",
      "filter category: 100%|██████████| 12/12 [00:00<00:00, 3983.83it/s]\n",
      "filter category: 100%|██████████| 12/12 [00:00<00:00, 3982.25it/s]\n",
      "filter category: 100%|██████████| 13/13 [00:00<00:00, 2958.22it/s]\n",
      "filter category: 100%|██████████| 11/11 [00:00<00:00, 3674.82it/s]\n",
      "filter category: 100%|██████████| 14/14 [00:00<00:00, 2800.87it/s]\n",
      "filter category: 100%|██████████| 11/11 [00:00<00:00, 4356.28it/s]\n",
      "filter category: 100%|██████████| 11/11 [00:00<00:00, 7264.58it/s]\n",
      "filter category: 100%|██████████| 14/14 [00:00<00:00, 2836.86it/s]\n",
      "filter category: 100%|██████████| 11/11 [00:00<00:00, 5520.14it/s]\n",
      "filter category: 100%|██████████| 11/11 [00:00<00:00, 3137.95it/s]\n",
      "filter category: 100%|██████████| 14/14 [00:00<00:00, 3208.76it/s]\n",
      "filter category: 100%|██████████| 12/12 [00:00<00:00, 4759.04it/s]\n",
      "filter category: 100%|██████████| 12/12 [00:00<00:00, 4749.16it/s]\n",
      "filter category: 100%|██████████| 12/12 [00:00<00:00, 6003.30it/s]\n",
      "filter category: 100%|██████████| 14/14 [00:00<00:00, 4675.18it/s]\n",
      "filter category: 100%|██████████| 13/13 [00:00<00:00, 6279.62it/s]\n",
      "filter category: 100%|██████████| 11/11 [00:00<00:00, 5498.43it/s]\n",
      "filter category: 100%|██████████| 12/12 [00:00<00:00, 2842.95it/s]\n",
      "filter category: 100%|██████████| 14/14 [00:00<00:00, 4664.78it/s]\n",
      "filter category: 100%|██████████| 13/13 [00:00<00:00, 2873.42it/s]\n",
      "filter category: 100%|██████████| 11/11 [00:00<00:00, 4393.61it/s]\n",
      "filter category: 100%|██████████| 10/10 [00:00<00:00, 3331.19it/s]\n",
      "filter category: 100%|██████████| 13/13 [00:00<00:00, 2582.45it/s]\n",
      "filter category: 100%|██████████| 14/14 [00:00<00:00, 3488.82it/s]\n",
      "filter category: 100%|██████████| 13/13 [00:00<00:00, 6038.31it/s]\n",
      "filter category: 100%|██████████| 11/11 [00:00<00:00, 5420.91it/s]\n",
      "filter category: 100%|██████████| 11/11 [00:00<00:00, 4364.93it/s]\n",
      "filter category: 100%|██████████| 14/14 [00:00<00:00, 7059.42it/s]\n",
      "filter category: 100%|██████████| 14/14 [00:00<00:00, 13991.01it/s]\n",
      "filter category: 100%|██████████| 14/14 [00:00<00:00, 3483.43it/s]\n",
      "filter category: 100%|██████████| 10/10 [00:00<00:00, 3969.25it/s]\n",
      "filter category: 100%|██████████| 9/9 [00:00<00:00, 4497.11it/s]\n",
      "filter category: 100%|██████████| 12/12 [00:00<00:00, 6366.26it/s]\n",
      "filter category: 100%|██████████| 13/13 [00:00<00:00, 5156.12it/s]\n",
      "filter category: 100%|██████████| 14/14 [00:00<00:00, 4669.23it/s]\n",
      "filter category: 100%|██████████| 9/9 [00:00<00:00, 4558.48it/s]\n",
      "filter category: 100%|██████████| 12/12 [00:00<00:00, 11986.58it/s]\n",
      "filter category: 100%|██████████| 12/12 [00:00<00:00, 4011.77it/s]\n",
      "filter category: 100%|██████████| 13/13 [00:00<00:00, 5147.84it/s]\n",
      "filter category: 100%|██████████| 10/10 [00:00<00:00, 2484.34it/s]\n",
      "filter category: 100%|██████████| 11/11 [00:00<00:00, 2024.19it/s]\n",
      "filter category: 100%|██████████| 10/10 [00:00<00:00, 9820.43it/s]\n",
      "filter category: 100%|██████████| 12/12 [00:00<00:00, 7848.38it/s]\n",
      "filter category: 100%|██████████| 13/13 [00:00<00:00, 4341.24it/s]\n",
      "filter category: 100%|██████████| 12/12 [00:00<00:00, 3979.42it/s]\n",
      "filter category: 100%|██████████| 14/14 [00:00<00:00, 4563.28it/s]\n",
      "filter category: 100%|██████████| 13/13 [00:00<00:00, 3711.27it/s]\n",
      "filter category: 100%|██████████| 12/12 [00:00<00:00, 2747.36it/s]\n",
      "filter category: 100%|██████████| 12/12 [00:00<00:00, 3959.07it/s]\n",
      "filter category: 100%|██████████| 9/9 [00:00<00:00, 4497.11it/s]\n",
      "filter category: 100%|██████████| 11/11 [00:00<00:00, 2752.17it/s]\n",
      "filter category: 100%|██████████| 13/13 [00:00<00:00, 4339.86it/s]\n",
      "filter category: 100%|██████████| 10/10 [00:00<00:00, 4963.67it/s]\n",
      "filter category: 100%|██████████| 13/13 [00:00<00:00, 6513.67it/s]\n",
      "filter category: 100%|██████████| 10/10 [00:00<00:00, 4956.63it/s]\n",
      "filter category: 100%|██████████| 10/10 [00:00<00:00, 5009.92it/s]\n",
      "filter category: 100%|██████████| 13/13 [00:00<00:00, 3238.46it/s]\n",
      "filter category: 100%|██████████| 15/15 [00:00<00:00, 4248.11it/s]\n",
      "filter category: 100%|██████████| 9/9 [00:00<00:00, 9052.45it/s]\n",
      "filter category: 100%|██████████| 12/12 [00:00<00:00, 6012.62it/s]\n",
      "filter category: 100%|██████████| 10/10 [00:00<00:00, 3333.05it/s]\n",
      "filter category: 100%|██████████| 12/12 [00:00<00:00, 3125.80it/s]\n",
      "filter category: 100%|██████████| 11/11 [00:00<00:00, 3650.40it/s]\n",
      "filter category: 100%|██████████| 14/14 [00:00<00:00, 4577.86it/s]\n",
      "filter category: 100%|██████████| 10/10 [00:00<00:00, 2392.37it/s]\n",
      "filter category: 100%|██████████| 12/12 [00:00<00:00, 3417.88it/s]\n",
      "filter category: 100%|██████████| 10/10 [00:00<00:00, 2737.98it/s]\n",
      "filter category: 100%|██████████| 8/8 [00:00<00:00, 4002.68it/s]\n",
      "filter category: 100%|██████████| 10/10 [00:00<00:00, 4560.51it/s]\n",
      "filter category: 100%|██████████| 12/12 [00:00<00:00, 3524.63it/s]\n",
      "filter category: 100%|██████████| 9/9 [00:00<00:00, 2978.67it/s]\n",
      "filter category: 100%|██████████| 10/10 [00:00<00:00, 4993.22it/s]\n",
      "filter category: 100%|██████████| 11/11 [00:00<00:00, 3129.44it/s]\n",
      "filter category: 100%|██████████| 12/12 [00:00<00:00, 5949.37it/s]\n",
      "filter category: 100%|██████████| 11/11 [00:00<00:00, 3101.25it/s]\n",
      "filter category: 100%|██████████| 13/13 [00:00<00:00, 4329.17it/s]\n",
      "filter category: 100%|██████████| 11/11 [00:00<00:00, 1681.21it/s]\n",
      "filter category: 100%|██████████| 11/11 [00:00<00:00, 4367.41it/s]\n",
      "filter category: 100%|██████████| 14/14 [00:00<00:00, 3092.98it/s]\n",
      "filter category: 100%|██████████| 12/12 [00:00<00:00, 3992.36it/s]\n",
      "filter category: 100%|██████████| 7/7 [00:00<00:00, 1743.16it/s]\n",
      "filter category: 100%|██████████| 10/10 [00:00<00:00, 4992.03it/s]\n",
      "filter category: 100%|██████████| 9/9 [00:00<00:00, 2997.60it/s]\n",
      "filter category: 100%|██████████| 11/11 [00:00<00:00, 3110.87it/s]\n",
      "filter category: 100%|██████████| 12/12 [00:00<00:00, 6003.30it/s]\n",
      "filter category: 100%|██████████| 8/8 [00:00<00:00, 2344.50it/s]\n",
      "filter category: 100%|██████████| 15/15 [00:00<00:00, 3391.99it/s]\n",
      "filter category: 100%|██████████| 12/12 [00:00<00:00, 3996.48it/s]\n",
      "filter category: 100%|██████████| 11/11 [00:00<00:00, 4679.24it/s]\n",
      "filter category: 100%|██████████| 13/13 [00:00<00:00, 4331.58it/s]\n",
      "filter category: 100%|██████████| 10/10 [00:00<00:00, 2829.59it/s]\n",
      "filter category: 100%|██████████| 12/12 [00:00<00:00, 2464.22it/s]\n",
      "filter category: 100%|██████████| 10/10 [00:00<00:00, 3023.79it/s]\n",
      "filter category: 100%|██████████| 12/12 [00:00<00:00, 5965.59it/s]\n",
      "filter category: 100%|██████████| 11/11 [00:00<00:00, 5499.09it/s]\n",
      "filter category: 100%|██████████| 11/11 [00:00<00:00, 3621.46it/s]\n",
      "filter category: 100%|██████████| 10/10 [00:00<00:00, 9747.39it/s]\n",
      "filter category: 100%|██████████| 11/11 [00:00<00:00, 2750.04it/s]\n",
      "filter category: 100%|██████████| 12/12 [00:00<00:00, 5541.91it/s]\n",
      "filter category: 100%|██████████| 11/11 [00:00<00:00, 5506.31it/s]\n",
      "filter category: 100%|██████████| 12/12 [00:00<00:00, 3709.58it/s]\n",
      "filter category: 100%|██████████| 12/12 [00:00<00:00, 2393.90it/s]\n",
      "filter category: 100%|██████████| 13/13 [00:00<00:00, 4338.13it/s]\n",
      "filter category: 100%|██████████| 12/12 [00:00<00:00, 4705.21it/s]\n",
      "filter category: 100%|██████████| 12/12 [00:00<00:00, 3978.79it/s]\n",
      "filter category: 100%|██████████| 11/11 [00:00<00:00, 3651.26it/s]\n",
      "filter category: 100%|██████████| 13/13 [00:00<00:00, 4138.91it/s]\n",
      "filter category: 100%|██████████| 13/13 [00:00<00:00, 2505.21it/s]\n",
      "filter category: 100%|██████████| 12/12 [00:00<00:00, 2638.48it/s]\n",
      "filter category: 100%|██████████| 12/12 [00:00<00:00, 4008.89it/s]\n",
      "filter category: 100%|██████████| 13/13 [00:00<00:00, 6512.89it/s]\n",
      "filter category: 100%|██████████| 12/12 [00:00<00:00, 2988.28it/s]\n",
      "filter category: 100%|██████████| 11/11 [00:00<00:00, 3643.76it/s]\n",
      "filter category: 100%|██████████| 13/13 [00:00<00:00, 4205.95it/s]\n",
      "filter category: 100%|██████████| 14/14 [00:00<00:00, 3482.20it/s]\n",
      "filter category: 100%|██████████| 11/11 [00:00<00:00, 3668.97it/s]\n",
      "filter category: 100%|██████████| 13/13 [00:00<00:00, 5268.72it/s]\n",
      "filter category: 100%|██████████| 12/12 [00:00<00:00, 5952.89it/s]\n",
      "filter category: 100%|██████████| 12/12 [00:00<00:00, 4773.03it/s]\n",
      "filter category: 100%|██████████| 13/13 [00:00<00:00, 3704.46it/s]\n",
      "filter category: 100%|██████████| 11/11 [00:00<00:00, 5511.57it/s]\n",
      "filter category: 100%|██████████| 12/12 [00:00<00:00, 3980.04it/s]\n",
      "filter category: 100%|██████████| 13/13 [00:00<00:00, 6407.28it/s]\n",
      "filter category: 100%|██████████| 12/12 [00:00<00:00, 3999.34it/s]\n",
      "filter category: 100%|██████████| 11/11 [00:00<00:00, 2419.49it/s]\n",
      "filter category: 100%|██████████| 13/13 [00:00<00:00, 4331.93it/s]\n",
      "filter category: 100%|██████████| 12/12 [00:00<00:00, 3999.34it/s]\n",
      "filter category: 100%|██████████| 12/12 [00:00<00:00, 3949.75it/s]\n",
      "filter category: 100%|██████████| 12/12 [00:00<00:00, 3995.53it/s]\n",
      "filter category: 100%|██████████| 11/11 [00:00<00:00, 2705.21it/s]\n",
      "filter category: 100%|██████████| 13/13 [00:00<00:00, 3245.79it/s]\n",
      "filter category: 100%|██████████| 12/12 [00:00<00:00, 2348.00it/s]\n",
      "filter category: 100%|██████████| 13/13 [00:00<00:00, 4336.75it/s]\n",
      "filter category: 100%|██████████| 12/12 [00:00<00:00, 4007.62it/s]\n",
      "filter category: 100%|██████████| 12/12 [00:00<00:00, 1977.12it/s]\n",
      "filter category: 100%|██████████| 13/13 [00:00<00:00, 4335.72it/s]\n",
      "filter category: 100%|██████████| 11/11 [00:00<00:00, 5185.72it/s]\n",
      "filter category: 100%|██████████| 13/13 [00:00<00:00, 6495.82it/s]\n",
      "filter category: 100%|██████████| 13/13 [00:00<00:00, 6447.43it/s]\n",
      "filter category: 100%|██████████| 12/12 [00:00<00:00, 2648.62it/s]\n",
      "filter category: 100%|██████████| 12/12 [00:00<00:00, 3637.99it/s]\n",
      "filter category: 100%|██████████| 13/13 [00:00<00:00, 6465.78it/s]\n",
      "filter category: 100%|██████████| 12/12 [00:00<00:00, 2645.00it/s]\n",
      "filter category: 100%|██████████| 13/13 [00:00<00:00, 3254.31it/s]\n",
      "filter category: 100%|██████████| 12/12 [00:00<00:00, 3994.89it/s]\n",
      "filter category: 100%|██████████| 11/11 [00:00<00:00, 5497.12it/s]\n",
      "filter category: 100%|██████████| 13/13 [00:00<00:00, 3837.42it/s]\n",
      "filter category: 100%|██████████| 13/13 [00:00<00:00, 4331.93it/s]\n",
      "filter category: 100%|██████████| 13/13 [00:00<00:00, 2338.86it/s]\n",
      "filter category: 100%|██████████| 12/12 [00:00<00:00, 4738.88it/s]\n",
      "filter category: 100%|██████████| 13/13 [00:00<00:00, 3687.42it/s]\n",
      "filter category: 100%|██████████| 12/12 [00:00<00:00, 5969.83it/s]\n",
      "filter category: 100%|██████████| 13/13 [00:00<00:00, 5142.02it/s]\n",
      "filter category: 100%|██████████| 12/12 [00:00<00:00, 2868.88it/s]\n",
      "filter category: 100%|██████████| 12/12 [00:00<00:00, 3244.69it/s]\n",
      "filter category: 100%|██████████| 12/12 [00:00<00:00, 1834.51it/s]\n",
      "filter category: 100%|██████████| 12/12 [00:00<00:00, 2400.86it/s]\n",
      "filter category: 100%|██████████| 13/13 [00:00<00:00, 4310.01it/s]\n",
      "filter category: 100%|██████████| 12/12 [00:00<00:00, 2392.30it/s]\n",
      "filter category: 100%|██████████| 14/14 [00:00<00:00, 2769.69it/s]\n",
      "filter category: 100%|██████████| 12/12 [00:00<00:00, 4897.98it/s]\n",
      "filter category: 100%|██████████| 13/13 [00:00<00:00, 3237.69it/s]\n",
      "filter category: 100%|██████████| 13/13 [00:00<00:00, 5166.87it/s]\n",
      "filter category: 100%|██████████| 12/12 [00:00<00:00, 2615.85it/s]\n",
      "filter category: 100%|██████████| 13/13 [00:00<00:00, 3160.01it/s]\n",
      "filter category: 100%|██████████| 13/13 [00:00<00:00, 1991.74it/s]\n",
      "filter category: 100%|██████████| 13/13 [00:00<00:00, 2163.38it/s]\n",
      "filter category: 100%|██████████| 11/11 [00:00<00:00, 4640.65it/s]\n",
      "filter category: 100%|██████████| 12/12 [00:00<00:00, 3645.64it/s]\n",
      "filter category: 100%|██████████| 13/13 [00:00<00:00, 3250.24it/s]\n",
      "filter category: 100%|██████████| 13/13 [00:00<00:00, 4332.96it/s]\n",
      "filter category: 100%|██████████| 12/12 [00:00<00:00, 2351.95it/s]\n",
      "filter category: 100%|██████████| 11/11 [00:00<00:00, 3135.82it/s]\n",
      "filter category: 100%|██████████| 13/13 [00:00<00:00, 2598.83it/s]\n",
      "filter category: 100%|██████████| 13/13 [00:00<00:00, 4081.89it/s]\n",
      "filter category: 100%|██████████| 11/11 [00:00<00:00, 11008.67it/s]\n",
      "filter category: 100%|██████████| 14/14 [00:00<00:00, 4647.06it/s]\n",
      "filter category: 100%|██████████| 9/9 [00:00<00:00, 3584.53it/s]\n",
      "filter category: 100%|██████████| 10/10 [00:00<00:00, 2832.84it/s]\n",
      "filter category: 100%|██████████| 12/12 [00:00<00:00, 3978.79it/s]\n",
      "filter category: 100%|██████████| 12/12 [00:00<00:00, 3728.55it/s]\n",
      "filter category: 100%|██████████| 12/12 [00:00<00:00, 6029.91it/s]\n",
      "filter category: 100%|██████████| 12/12 [00:00<00:00, 3996.16it/s]\n",
      "filter category: 100%|██████████| 11/11 [00:00<00:00, 3668.39it/s]\n",
      "filter category: 100%|██████████| 12/12 [00:00<00:00, 2659.67it/s]\n",
      "filter category: 100%|██████████| 11/11 [00:00<00:00, 390.85it/s]\n",
      "filter category: 100%|██████████| 11/11 [00:00<00:00, 3651.84it/s]\n",
      "filter category: 100%|██████████| 10/10 [00:00<00:00, 5006.33it/s]\n",
      "filter category: 100%|██████████| 11/11 [00:00<00:00, 2718.28it/s]\n",
      "filter category: 100%|██████████| 13/13 [00:00<00:00, 4314.44it/s]\n",
      "filter category: 100%|██████████| 13/13 [00:00<00:00, 3009.32it/s]\n",
      "filter category: 100%|██████████| 11/11 [00:00<00:00, 3670.73it/s]\n",
      "filter category: 100%|██████████| 12/12 [00:00<00:00, 5828.12it/s]\n",
      "filter category: 100%|██████████| 13/13 [00:00<00:00, 4317.86it/s]\n",
      "filter category: 100%|██████████| 13/13 [00:00<00:00, 3775.77it/s]\n",
      "filter category: 100%|██████████| 11/11 [00:00<00:00, 3650.11it/s]\n",
      "filter category: 100%|██████████| 12/12 [00:00<00:00, 5998.29it/s]\n",
      "filter category: 100%|██████████| 11/11 [00:00<00:00, 3557.78it/s]\n",
      "filter category: 100%|██████████| 11/11 [00:00<00:00, 2432.63it/s]\n",
      "filter category: 100%|██████████| 10/10 [00:00<00:00, 4997.38it/s]\n",
      "filter category: 100%|██████████| 10/10 [00:00<00:00, 3329.61it/s]\n",
      "filter category: 100%|██████████| 11/11 [00:00<00:00, 3674.53it/s]\n",
      "filter category: 100%|██████████| 12/12 [00:00<00:00, 4776.20it/s]\n",
      "filter category: 100%|██████████| 12/12 [00:00<00:00, 3885.71it/s]\n",
      "filter category: 100%|██████████| 12/12 [00:00<00:00, 2974.86it/s]\n",
      "filter category: 100%|██████████| 13/13 [00:00<00:00, 6498.15it/s]\n",
      "filter category: 100%|██████████| 12/12 [00:00<00:00, 4003.79it/s]\n",
      "filter category: 100%|██████████| 11/11 [00:00<00:00, 3662.57it/s]\n",
      "filter category: 100%|██████████| 11/11 [00:00<00:00, 4376.11it/s]\n",
      "filter category: 100%|██████████| 13/13 [00:00<00:00, 6455.07it/s]\n",
      "filter category: 100%|██████████| 12/12 [00:00<00:00, 4006.98it/s]\n",
      "filter category: 100%|██████████| 11/11 [00:00<00:00, 4352.58it/s]\n",
      "filter category: 100%|██████████| 12/12 [00:00<00:00, 2652.66it/s]\n",
      "filter category: 100%|██████████| 12/12 [00:00<00:00, 4003.47it/s]\n",
      "filter category: 100%|██████████| 12/12 [00:00<00:00, 3004.34it/s]\n",
      "filter category: 100%|██████████| 13/13 [00:00<00:00, 4313.76it/s]\n",
      "filter category: 100%|██████████| 13/13 [00:00<00:00, 4337.09it/s]\n",
      "filter category: 100%|██████████| 13/13 [00:00<00:00, 3667.09it/s]\n",
      "filter category: 100%|██████████| 11/11 [00:00<00:00, 5491.89it/s]\n",
      "filter category: 100%|██████████| 12/12 [00:00<00:00, 4738.43it/s]\n",
      "filter category: 100%|██████████| 11/11 [00:00<00:00, 5504.34it/s]\n",
      "filter category: 100%|██████████| 11/11 [00:00<00:00, 3907.96it/s]\n",
      "filter category: 100%|██████████| 10/10 [00:00<00:00, 3319.59it/s]\n",
      "filter category: 100%|██████████| 12/12 [00:00<00:00, 2399.60it/s]\n",
      "filter category: 100%|██████████| 12/12 [00:00<00:00, 5993.29it/s]\n",
      "filter category: 100%|██████████| 12/12 [00:00<00:00, 3577.49it/s]\n",
      "filter category: 100%|██████████| 10/10 [00:00<00:00, 3307.55it/s]\n",
      "filter category: 100%|██████████| 13/13 [00:00<00:00, 2359.31it/s]\n",
      "filter category: 100%|██████████| 12/12 [00:00<00:00, 5957.11it/s]\n",
      "filter category: 100%|██████████| 12/12 [00:00<00:00, 2650.57it/s]\n",
      "filter category: 100%|██████████| 12/12 [00:00<00:00, 3309.12it/s]\n",
      "filter category: 100%|██████████| 13/13 [00:00<00:00, 5302.02it/s]\n",
      "filter category: 100%|██████████| 12/12 [00:00<00:00, 3826.05it/s]\n",
      "filter category: 100%|██████████| 13/13 [00:00<00:00, 3695.67it/s]\n",
      "filter category: 100%|██████████| 11/11 [00:00<00:00, 5478.19it/s]\n",
      "filter category: 100%|██████████| 13/13 [00:00<00:00, 13075.77it/s]\n",
      "filter category: 100%|██████████| 11/11 [00:00<00:00, 4716.07it/s]\n",
      "filter category: 100%|██████████| 12/12 [00:00<00:00, 4009.21it/s]\n",
      "filter category: 100%|██████████| 13/13 [00:00<00:00, 1989.20it/s]\n",
      "filter category: 100%|██████████| 12/12 [00:00<00:00, 5991.15it/s]\n",
      "filter category: 100%|██████████| 10/10 [00:00<00:00, 2978.49it/s]\n",
      "filter category: 100%|██████████| 11/11 [00:00<00:00, 2428.54it/s]\n",
      "filter category: 100%|██████████| 10/10 [00:00<00:00, 4979.58it/s]\n",
      "filter category: 100%|██████████| 12/12 [00:00<00:00, 5927.65it/s]\n",
      "filter category: 100%|██████████| 12/12 [00:00<00:00, 2352.61it/s]\n",
      "filter category: 100%|██████████| 11/11 [00:00<00:00, 5258.42it/s]\n",
      "filter category: 100%|██████████| 11/11 [00:00<00:00, 3663.73it/s]\n",
      "filter category: 100%|██████████| 12/12 [00:00<00:00, 3397.80it/s]\n",
      "filter category: 100%|██████████| 12/12 [00:00<00:00, 5986.16it/s]\n",
      "filter category: 100%|██████████| 12/12 [00:00<00:00, 5945.85it/s]\n",
      "filter category: 100%|██████████| 12/12 [00:00<00:00, 2987.04it/s]\n",
      "filter category: 100%|██████████| 13/13 [00:00<00:00, 3254.31it/s]\n",
      "filter category: 100%|██████████| 13/13 [00:00<00:00, 4327.11it/s]\n",
      "filter category: 100%|██████████| 12/12 [00:00<00:00, 5989.01it/s]\n",
      "filter category: 100%|██████████| 12/12 [00:00<00:00, 3004.34it/s]\n",
      "filter category: 100%|██████████| 13/13 [00:00<00:00, 6495.05it/s]\n",
      "filter category: 100%|██████████| 12/12 [00:00<00:00, 6027.02it/s]\n",
      "filter category: 100%|██████████| 11/11 [00:00<00:00, 4335.40it/s]\n",
      "filter category: 100%|██████████| 13/13 [00:00<00:00, 4323.34it/s]\n",
      "filter category: 100%|██████████| 12/12 [00:00<00:00, 4782.56it/s]\n",
      "filter category: 100%|██████████| 12/12 [00:00<00:00, 1827.38it/s]\n",
      "filter category: 100%|██████████| 13/13 [00:00<00:00, 3251.20it/s]\n",
      "filter category: 100%|██████████| 13/13 [00:00<00:00, 4313.42it/s]\n",
      "filter category: 100%|██████████| 12/12 [00:00<00:00, 2658.13it/s]\n",
      "filter category: 100%|██████████| 13/13 [00:00<00:00, 4953.30it/s]\n",
      "filter category: 100%|██████████| 13/13 [00:00<00:00, 6495.82it/s]\n",
      "filter category: 100%|██████████| 12/12 [00:00<00:00, 1604.55it/s]\n",
      "filter category: 100%|██████████| 13/13 [00:00<00:00, 3252.56it/s]\n",
      "filter category: 100%|██████████| 12/12 [00:00<00:00, 3999.65it/s]\n",
      "filter category: 100%|██████████| 10/10 [00:00<00:00, 3661.87it/s]\n",
      "filter category: 100%|██████████| 12/12 [00:00<00:00, 4969.55it/s]\n",
      "filter category: 100%|██████████| 11/11 [00:00<00:00, 5493.85it/s]\n",
      "filter category: 100%|██████████| 13/13 [00:00<00:00, 3251.79it/s]\n",
      "filter category: 100%|██████████| 13/13 [00:00<00:00, 5298.41it/s]\n",
      "filter category: 100%|██████████| 13/13 [00:00<00:00, 2868.58it/s]\n",
      "filter category: 100%|██████████| 10/10 [00:00<00:00, 4219.20it/s]\n",
      "filter category: 100%|██████████| 12/12 [00:00<00:00, 4646.57it/s]\n",
      "filter category: 100%|██████████| 10/10 [00:00<00:00, 5011.12it/s]\n",
      "filter category: 100%|██████████| 11/11 [00:00<00:00, 3669.27it/s]\n",
      "filter category: 100%|██████████| 12/12 [00:00<00:00, 2998.61it/s]\n",
      "filter category: 100%|██████████| 13/13 [00:00<00:00, 5142.02it/s]\n",
      "filter category: 100%|██████████| 13/13 [00:00<00:00, 4330.89it/s]\n",
      "filter category: 100%|██████████| 12/12 [00:00<00:00, 5995.43it/s]\n",
      "filter category: 100%|██████████| 12/12 [00:00<00:00, 2651.83it/s]\n",
      "filter category: 100%|██████████| 12/12 [00:00<00:00, 4003.15it/s]\n",
      "filter category: 100%|██████████| 11/11 [00:00<00:00, 2748.72it/s]\n",
      "filter category: 100%|██████████| 11/11 [00:00<00:00, 4351.35it/s]\n",
      "filter category: 100%|██████████| 9/9 [00:00<00:00, 4496.04it/s]\n",
      "filter category: 100%|██████████| 11/11 [00:00<00:00, 5508.28it/s]\n",
      "filter category: 100%|██████████| 11/11 [00:00<00:00, 2739.42it/s]\n",
      "filter category: 100%|██████████| 12/12 [00:00<00:00, 4005.70it/s]\n",
      "filter category: 100%|██████████| 12/12 [00:00<00:00, 3407.46it/s]\n",
      "filter category: 100%|██████████| 11/11 [00:00<00:00, 5501.05it/s]\n",
      "filter category: 100%|██████████| 12/12 [00:00<00:00, 4778.47it/s]\n",
      "filter category: 100%|██████████| 12/12 [00:00<00:00, 3005.05it/s]\n",
      "filter category: 100%|██████████| 12/12 [00:00<00:00, 2390.37it/s]\n",
      "filter category: 100%|██████████| 11/11 [00:00<00:00, 3691.28it/s]\n",
      "filter category: 100%|██████████| 12/12 [00:00<00:00, 2979.97it/s]\n",
      "filter category: 100%|██████████| 10/10 [00:00<00:00, 3947.58it/s]\n",
      "filter category: 100%|██████████| 12/12 [00:00<00:00, 5926.95it/s]\n",
      "filter category: 100%|██████████| 12/12 [00:00<00:00, 3673.57it/s]\n",
      "filter category: 100%|██████████| 11/11 [00:00<00:00, 2721.81it/s]\n",
      "filter category: 100%|██████████| 11/11 [00:00<00:00, 2339.86it/s]\n",
      "filter category: 100%|██████████| 10/10 [00:00<00:00, 1998.62it/s]\n",
      "filter category: 100%|██████████| 11/11 [00:00<00:00, 3126.68it/s]\n",
      "filter category: 100%|██████████| 12/12 [00:00<00:00, 3995.21it/s]\n",
      "filter category: 100%|██████████| 12/12 [00:00<00:00, 5953.59it/s]\n",
      "scarpe fight: 100%|██████████| 449/449 [07:30<00:00,  1.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collected 257 stats links.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['http://ufcstats.com/fight-details/cb902d73389ed34b',\n",
       " 'http://ufcstats.com/fight-details/ecdbb3a5216b815e',\n",
       " 'http://ufcstats.com/fight-details/7cbfeba85f86d1bf',\n",
       " 'http://ufcstats.com/fight-details/202c47db69768356',\n",
       " 'http://ufcstats.com/fight-details/69b31593175f77ec']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "fight_row =[]\n",
    "stats_link =[]\n",
    "\n",
    "for match in tqdm(match_links, desc=\"scarpe fight\"):\n",
    "    response = requests.get(match)\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "    #in each match link table\n",
    "    #find all right row\n",
    "    fight_rows = soup.find_all('tr', class_=\"b-fight-details__table-row b-fight-details__table-row__hover js-fight-details-click\")\n",
    "    fight_row.append(fight_rows)\n",
    "\n",
    "    for row in tqdm(fight_rows, desc=\"filter category\"):\n",
    "        tds = row.find_all(\"td\") #find all td in each fight row\n",
    "        if len(tds) >= 9: #total row is 9 - 0~9\n",
    "            #get data in each row\n",
    "            #get weight in 6 row. find the p tag with info\n",
    "            weight_class = tds[6].find(\"p\").get_text(strip=True)\n",
    "            #get method in 7 row. have 2 p tag get the first one\n",
    "            method = tds[7].find_all(\"p\")[0].get_text(strip=True)\n",
    "            #get total round in 8 row\n",
    "            total_round = tds[8].find(\"p\").get_text(strip=True) #1,2,3 - total round that ends\n",
    "\n",
    "            #get only matching category\n",
    "            category = weight_class == \"Lightweight\" and (method in [\"KO/TKO\", \"KO\", \"TKO\"])\n",
    "            if category:\n",
    "                #print(\"match found\",weight_class, method)\n",
    "                #get data link to go to the stats table and extract data \n",
    "                data_link = row.get(\"data-link\") # all fight link that matched the category\n",
    "                #print(data_link)\n",
    "                stats_link.append(data_link)\n",
    "\n",
    "print(f\"Collected {len(stats_link)} stats links.\")\n",
    "stats_link[:5] #print first 5 stats links\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f89384",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ffcd450",
   "metadata": {},
   "outputs": [],
   "source": [
    "#go in each filtered stats_link get the data\n",
    "# req again with the fight link to go to stats table\n",
    "for all_stats in stats_link:\n",
    "    response = requests.get(all_stats)\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "    # extract data in stats table page for top div \n",
    "    fight_details = soup.find(\"div\", class_=\"b-fight-details__fight\")\n",
    "    if fight_details:\n",
    "        # get round num\n",
    "        total_round = fight_details.find(\"i\", class_=\"b-fight-details__text-item\").get_text(strip=True)\n",
    "        # get method ko/tko\n",
    "        method_tag = fight_details.find(\"i\", attrs={\"style\": \"font-style: normal\"})\n",
    "        method = method_tag.get_text(strip=True) if method_tag else \"-\"\n",
    "\n",
    "    # extract data from table\n",
    "    table_stats = soup.find_all(\"table\", class_=\"b-fight-details__table js-fight-table\")\n",
    "    #print(len(table_stats)) #2\n",
    "    table1= table_stats[0] #top totals table third table\n",
    "    table2= table_stats[1] #significant table body attack forth table\n",
    "    #extract data for one match from 2 table. \n",
    "    #now need to do this for all match \n",
    "\n",
    "    #save data\n",
    "    kd_list, sig_str_list, sig_str_pct_list, total_str_list = [], [], [], []\n",
    "    td_attempt_list, td_pct_list, sub_att_list, rev_list, ctrl_sec_list = [], [], [], [], []\n",
    "    head_list, body_list, leg_list, distance_list, clinch_list, ground_list = [], [], [], [], [], []\n",
    "\n",
    "\n",
    "    if table1:\n",
    "        t1_row = table1.find_all(\"tr\", class_=\"b-fight-details__table-row\")\n",
    "        for section in t1_row:\n",
    "            #round_num = section.find(\"tr\", class_=\"b-fight-details__table-col\").get_text(strip=True) # get round num tr\n",
    "            td_stats = section.find_all(\"td\")\n",
    "            if len(td_stats) >= 10:  # total col is 10\n",
    "                # get data in each row ex: round 1\n",
    "                kd = [p.get_text(strip=True) for p in td_stats[1].find_all(\"p\")]\n",
    "                sig_str = [p.get_text(strip=True) for p in td_stats[2].find_all(\"p\")]\n",
    "                sig_str_pct = [p.get_text(strip=True) for p in td_stats[3].find_all(\"p\")]\n",
    "                total_str = [p.get_text(strip=True) for p in td_stats[4].find_all(\"p\")]\n",
    "                td_attempt = [p.get_text(strip=True) for p in td_stats[5].find_all(\"p\")]\n",
    "                td_pct = [p.get_text(strip=True) for p in td_stats[6].find_all(\"p\")]\n",
    "                sub_att = [p.get_text(strip=True) for p in td_stats[7].find_all(\"p\")]\n",
    "                rev = [p.get_text(strip=True) for p in td_stats[8].find_all(\"p\")]\n",
    "                ctrl_sec = [p.get_text(strip=True) for p in td_stats[9].find_all(\"p\")]\n",
    "                # each list above has [fighter1, fighter2]\n",
    "                # append each row data\n",
    "                kd_list.append(kd)\n",
    "                sig_str_list.append(sig_str)\n",
    "                sig_str_pct_list.append(sig_str_pct)\n",
    "                total_str_list.append(total_str)\n",
    "                td_attempt_list.append(td_attempt)\n",
    "                td_pct_list.append(td_pct)\n",
    "                sub_att_list.append(sub_att)\n",
    "                rev_list.append(rev)\n",
    "                ctrl_sec_list.append(ctrl_sec)\n",
    "\n",
    "    if table2:\n",
    "        t2_row = table2.find_all(\"tr\", class_=\"b-fight-details__table-row\")               \n",
    "        for section2 in t2_row:\n",
    "            #round_num2 = section2.find(\"tr\", class_=\"b-fight-details__table-col\").get_text(strip=True) # get round num tr\n",
    "            td_stats_2 = section2.find_all(\"td\")\n",
    "            if len(td_stats_2) >= 8:\n",
    "                #get body attack data\n",
    "                head = [p.get_text(strip=True) for p in td_stats_2[3].find_all(\"p\")]\n",
    "                body = [p.get_text(strip=True) for p in td_stats_2[4].find_all(\"p\")]\n",
    "                leg = [p.get_text(strip=True) for p in td_stats_2[5].find_all(\"p\")]\n",
    "                distance = [p.get_text(strip=True) for p in td_stats_2[6].find_all(\"p\")]\n",
    "                clinch = [p.get_text(strip=True) for p in td_stats_2[7].find_all(\"p\")]\n",
    "                ground = [p.get_text(strip=True) for p in td_stats_2[8].find_all(\"p\")]\n",
    "\n",
    "                # append each row data\n",
    "                head_list.append(head)\n",
    "                body_list.append(body)\n",
    "                leg_list.append(leg)\n",
    "                distance_list.append(distance)\n",
    "                clinch_list.append(clinch)\n",
    "                ground_list.append(ground)\n",
    "\n",
    "    print(\n",
    "        \"new fight-\",\n",
    "        \"total_round:\", total_round,\n",
    "        \"KD:\", kd_list,\n",
    "        \"Sig.Str (L/A):\", sig_str_list,\n",
    "        \"sig_str_pct:\", sig_str_pct_list,\n",
    "        \"total_str (L/A):\", total_str_list,\n",
    "        \"td (L/A):\", td_attempt_list,\n",
    "        \"td_pct:\", td_pct_list,\n",
    "        \"sub_att:\", sub_att_list,\n",
    "        \"rev:\", rev_list,\n",
    "        \"Control(sec):\", ctrl_sec_list,\n",
    "        \"head (L/A):\", head_list,\n",
    "        \"body (L/A):\", body_list,\n",
    "        \"leg (L/A):\", leg_list,\n",
    "        \"distance (L/A):\", distance_list,\n",
    "        \"clinch (L/A):\", clinch_list,\n",
    "        \"ground (L/A):\", ground_list,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a23b08ca",
   "metadata": {},
   "outputs": [],
   "source": [
    " # === CLEANING USING REGEX ===\n",
    "import re\n",
    "\n",
    "def split_of_list(lst):\n",
    "                                    \"\"\"Split ['22 of 41', '23 of 64'] → [[22, 41], [23, 64]]\"\"\"\n",
    "                                    clean = []\n",
    "                                    for val in lst:\n",
    "                                        match = re.findall(r'(\\d+)\\s*of\\s*(\\d+)', val)\n",
    "                                        if match:\n",
    "                                            clean.append([int(match[0][0]), int(match[0][1])])\n",
    "                                        else:\n",
    "                                            clean.append([0, 0])\n",
    "                                    return clean\n",
    "\n",
    "def clean_pct_list(lst):\n",
    "                                    \"\"\"Remove '%' and convert to float\"\"\"\n",
    "                                    return [float(re.sub(r'[^0-9.]', '', v)) if re.search(r'\\d', v) else 0.0 for v in lst]\n",
    "\n",
    "def clean_int_list(lst):\n",
    "                                    \"\"\"Convert list of strings to int\"\"\"\n",
    "                                    return [int(re.sub(r'\\D', '', v)) if re.search(r'\\d', v) else 0 for v in lst]\n",
    "\n",
    "def ctrl_to_seconds(lst):\n",
    "                                    \"\"\"Convert ['1:23', '0:45'] → [83, 45]\"\"\"\n",
    "                                    result = []\n",
    "                                    for v in lst:\n",
    "                                        match = re.findall(r'(\\d+):(\\d+)', v)\n",
    "                                        if match:\n",
    "                                            m, s = map(int, match[0])\n",
    "                                            result.append(m * 60 + s)\n",
    "                                        else:\n",
    "                                            result.append(0)\n",
    "                                    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9f7b422a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved ufc_totalround_1.csv (135 rows)\n",
      "✅ Saved ufc_totalround_3.csv (102 rows)\n",
      "✅ Saved ufc_totalround_2.csv (166 rows)\n"
     ]
    }
   ],
   "source": [
    "from itertools import zip_longest  # add if you want safer pairing (optional)\n",
    "import re\n",
    "import csv \n",
    "from collections import defaultdict\n",
    "\n",
    "fight_data = defaultdict(list)\n",
    "# go in each filtered stats_link get the data\n",
    "for all_stats in stats_link:\n",
    "    response = requests.get(all_stats)\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "    # extract data in stats table page for top div \n",
    "    fight_details = soup.find(\"div\", class_=\"b-fight-details__fight\")\n",
    "    if fight_details:\n",
    "        # get round num (total rounds)\n",
    "        total_round = fight_details.find(\"i\", class_=\"b-fight-details__text-item\").get_text(strip=True)\n",
    "        # get method ko/tko\n",
    "        method_tag = fight_details.find(\"i\", attrs={\"style\": \"font-style: normal\"})\n",
    "        method = method_tag.get_text(strip=True) if method_tag else \"-\"\n",
    "\n",
    "    # extract data from table\n",
    "    table_stats = soup.find_all(\"table\", class_=\"b-fight-details__table js-fight-table\")\n",
    "    if len(table_stats) < 2:\n",
    "        continue\n",
    "\n",
    "    table1 = table_stats[0]  # top totals table\n",
    "    table2 = table_stats[1]  # significant strikes table\n",
    "\n",
    "    # get all rows first\n",
    "    all_t1_rows = table1.find_all(\"tr\", class_=\"b-fight-details__table-row\")\n",
    "    all_t2_rows = table2.find_all(\"tr\", class_=\"b-fight-details__table-row\")\n",
    "\n",
    "    # FILTER rows to only keep \"data\" rows (avoid header/separator rows)\n",
    "    # table1 data rows must have at least 10 <td>, table2 data rows at least 9 <td>\n",
    "    t1_rows = [r for r in all_t1_rows if len(r.find_all(\"td\")) >= 10]\n",
    "    t2_rows = [r for r in all_t2_rows if len(r.find_all(\"td\")) >= 9]\n",
    "\n",
    "    # optional debug prints to confirm alignment (uncomment if needed)\n",
    "    # print(\"debug:\", all_stats, \"t1_rows:\", len(t1_rows), \"t2_rows:\", len(t2_rows))\n",
    "\n",
    "    # iterate data rows and pair by index\n",
    "    for idx, section in enumerate(t1_rows, start=1):\n",
    "        td_stats = section.find_all(\"td\")\n",
    "        # round number is idx\n",
    "        round_num = idx\n",
    "\n",
    "        kd = [p.get_text(strip=True) for p in td_stats[1].find_all(\"p\")]\n",
    "        sig_str = [p.get_text(strip=True) for p in td_stats[2].find_all(\"p\")]\n",
    "        sig_str_pct = [p.get_text(strip=True) for p in td_stats[3].find_all(\"p\")]\n",
    "        total_str = [p.get_text(strip=True) for p in td_stats[4].find_all(\"p\")]\n",
    "        td_attempt = [p.get_text(strip=True) for p in td_stats[5].find_all(\"p\")]\n",
    "        td_pct = [p.get_text(strip=True) for p in td_stats[6].find_all(\"p\")]\n",
    "        sub_att = [p.get_text(strip=True) for p in td_stats[7].find_all(\"p\")]\n",
    "        rev = [p.get_text(strip=True) for p in td_stats[8].find_all(\"p\")]\n",
    "        ctrl_sec = [p.get_text(strip=True) for p in td_stats[9].find_all(\"p\")]\n",
    "\n",
    "        # get matching table2 row if exists (safe access)\n",
    "        if round_num - 1 < len(t2_rows):\n",
    "            section2 = t2_rows[round_num - 1]\n",
    "            td_stats_2 = section2.find_all(\"td\")\n",
    "            if len(td_stats_2) >= 9:\n",
    "                head = [p.get_text(strip=True) for p in td_stats_2[3].find_all(\"p\")]\n",
    "                body = [p.get_text(strip=True) for p in td_stats_2[4].find_all(\"p\")]\n",
    "                leg = [p.get_text(strip=True) for p in td_stats_2[5].find_all(\"p\")]\n",
    "                distance = [p.get_text(strip=True) for p in td_stats_2[6].find_all(\"p\")]\n",
    "                clinch = [p.get_text(strip=True) for p in td_stats_2[7].find_all(\"p\")]\n",
    "                ground = [p.get_text(strip=True) for p in td_stats_2[8].find_all(\"p\")]\n",
    "            else:\n",
    "                head = body = leg = distance = clinch = ground = [\"-\", \"-\"]\n",
    "        else:\n",
    "            head = body = leg = distance = clinch = ground = [\"-\", \"-\"]\n",
    "\n",
    "        sig_str = split_of_list(sig_str)\n",
    "        total_str = split_of_list(total_str)\n",
    "        td_attempt = split_of_list(td_attempt)\n",
    "        sig_str_pct = clean_pct_list(sig_str_pct)\n",
    "        td_pct = clean_pct_list(td_pct)\n",
    "        sub_att = clean_int_list(sub_att)\n",
    "        rev = clean_int_list(rev)\n",
    "        kd = clean_int_list(kd)\n",
    "        ctrl_sec = ctrl_to_seconds(ctrl_sec)\n",
    "        head = split_of_list(head)\n",
    "        body = split_of_list(body)\n",
    "        leg = split_of_list(leg)\n",
    "        distance = split_of_list(distance)\n",
    "        clinch = split_of_list(clinch)\n",
    "        ground = split_of_list(ground)\n",
    "        total_round_c = total_round.replace(\"Round:\", \"\").strip()\n",
    "\n",
    "       # store the round data in dictionary\n",
    "        round_data = {\n",
    "            \"link\": all_stats,  # use the fight link as group key\n",
    "            \"round\": round_num,\n",
    "            \"kd\": kd,\n",
    "            \"sig_str\": sig_str,\n",
    "            \"sig_str_pct\": sig_str_pct,\n",
    "            \"total_str\": total_str,\n",
    "            \"td_attempt\": td_attempt,\n",
    "            \"td_pct\": td_pct,\n",
    "            \"sub_att\": sub_att,\n",
    "            \"rev\": rev,\n",
    "            \"ctrl_sec\": ctrl_sec,\n",
    "            \"head\": head,\n",
    "            \"body\": body,\n",
    "            \"leg\": leg,\n",
    "            \"distance\": distance,\n",
    "            \"clinch\": clinch,\n",
    "            \"ground\": ground,\n",
    "            \"total_round\": total_round_c,\n",
    "            \"method\": method\n",
    "        }\n",
    "\n",
    "        # group all rounds that belong to the same fight link\n",
    "        fight_data[all_stats].append(round_data)\n",
    "        time.sleep(0.5)\n",
    "\n",
    "fight_counter = 1\n",
    "fights_by_round_count = defaultdict(list)\n",
    "\n",
    "# Define your preferred column order\n",
    "columns = [\n",
    "    \"fight\",\n",
    "    \"round\",\n",
    "    \"kd\",\n",
    "    \"sig_str\",\n",
    "    \"sig_str_pct\",\n",
    "    \"total_str\",\n",
    "    \"td_attempt\",\n",
    "    \"td_pct\",\n",
    "    \"sub_att\",\n",
    "    \"rev\",\n",
    "    \"ctrl_sec\",\n",
    "    \"head\",\n",
    "    \"body\",\n",
    "    \"leg\",\n",
    "    \"distance\",\n",
    "    \"clinch\",\n",
    "    \"ground\",\n",
    "    \"total_round\",\n",
    "    \"method\"\n",
    "]\n",
    "\n",
    "for link, rounds in fight_data.items():\n",
    "    # total_round is same for the fight (use from first round)\n",
    "    total_round_c = rounds[0][\"total_round\"]\n",
    "    fight_name = f\"fight{fight_counter}\"\n",
    "\n",
    "    for r in rounds:\n",
    "        row = {\"fight\": fight_name, \"round\": r[\"round\"]}\n",
    "        for k, v in r.items():\n",
    "            if k not in [\"link\", \"round\", \"total_round\"]:\n",
    "                row[k] = v\n",
    "        fights_by_round_count[total_round_c].append(row)\n",
    "\n",
    "    fight_counter += 1\n",
    "\n",
    "# save grouped by total rounds\n",
    "for total_round_c, rows in fights_by_round_count.items():\n",
    "\n",
    "    if total_round_c in [\"4\", \"5\"]:\n",
    "        continue\n",
    "\n",
    "    filename = f\"ufc_totalround_{total_round_c}.csv\"\n",
    "    fieldnames = sorted(rows[0].keys())\n",
    "    \n",
    "\n",
    "    with open(filename, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=columns)\n",
    "        writer.writeheader()\n",
    "        writer.writerows(rows)\n",
    "\n",
    "    print(f\"✅ Saved {filename} ({len(rows)} rows)\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724a9fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fight_counter = 1\n",
    "fights_by_round_count = defaultdict(list)\n",
    "\n",
    "for link, rounds in fight_data.items():\n",
    "    # total_round is same for the fight (use from first round)\n",
    "    total_round = rounds[0][\"total_round\"]\n",
    "    fight_name = f\"fight{fight_counter}\"\n",
    "\n",
    "    for r in rounds:\n",
    "        row = {\"fight\": fight_name, \"round\": r[\"round\"]}\n",
    "        for k, v in r.items():\n",
    "            if k not in [\"link\", \"round\", \"total_round\"]:\n",
    "                row[k] = v\n",
    "        fights_by_round_count[total_round].append(row)\n",
    "\n",
    "    fight_counter += 1\n",
    "\n",
    "# save grouped by total rounds\n",
    "for total_round, rows in fights_by_round_count.items():\n",
    "    filename = f\"ufc_totalround_{total_round}.csv\"\n",
    "    fieldnames = sorted(rows[0].keys())\n",
    "\n",
    "    with open(filename, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        writer.writerows(rows)\n",
    "\n",
    "    print(f\"✅ Saved {filename} ({len(rows)} rows)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a9bd8105",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def save_to_csv(filename, data_list):\n",
    "    \"\"\"Save list of dicts to CSV if not empty.\"\"\"\n",
    "    if not data_list:\n",
    "        print(f\"⚠️ No data to save for {filename}\")\n",
    "        return\n",
    "    with open(filename, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=list(data_list[0].keys()))\n",
    "        writer.writeheader()\n",
    "        writer.writerows(data_list)\n",
    "    print(f\"✅ Saved {len(data_list)} rows → {filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e139825f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#req again with new link from matchlinks\n",
    "import re\n",
    "\n",
    "#fight_link=[]\n",
    "# define before your for-loop- to save \n",
    "round1_data, round2_data, round3_data = [], [], [] #save same fight that end with same total round in 1 file\n",
    "\n",
    "fight_rows = []\n",
    "for match in match_links:\n",
    "    response = requests.get(match)\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "    #in each match link table\n",
    "    #find all right row\n",
    "    fight_row = soup.find_all('tr', class_=\"b-fight-details__table-row b-fight-details__table-row__hover js-fight-details-click\")\n",
    "    fight_rows.append(fight_row)\n",
    "\n",
    "    for row in fight_rows:\n",
    "        tds = row.find_all(\"td\") #find all td in each fight row\n",
    "        if len(tds) >= 9: #total row is 9 - 0~9\n",
    "            #get data in each row\n",
    "            #get weight in 6 row. find the p tag with info\n",
    "            weight_class = tds[6].find(\"p\").get_text(strip=True)\n",
    "            #get method in 7 row. have 2 p tag get the first one\n",
    "            method = tds[7].find_all(\"p\")[0].get_text(strip=True)\n",
    "            #get total round in 8 row\n",
    "            total_round = tds[8].find(\"p\").get_text(strip=True) #1,2,3 - total round that ends\n",
    "\n",
    "            #get only matching category\n",
    "            category = weight_class == \"Lightweight\" and (method in [\"KO/TKO\", \"KO\", \"TKO\"])\n",
    "            if category:\n",
    "                #print(\"match found\",weight_class, method)\n",
    "                #get data link to go to the stats table and extract data \n",
    "                data_link = row.get(\"data-link\") # all fight link that matched the category\n",
    "                #print(data_link)\n",
    "\n",
    "                # req again with the fight link to go to stats table\n",
    "                data_link_response = requests.get(data_link)\n",
    "                soup = BeautifulSoup(data_link_response.text, \"html.parser\")\n",
    "\n",
    "                # extract data in stats table page\n",
    "                fight_details = soup.find(\"div\", class_=\"b-fight-details__fight\")\n",
    "                if fight_details:\n",
    "                    # get round num\n",
    "                    total_round = fight_details.find(\"i\", class_=\"b-fight-details__text-item\").get_text(strip=True)\n",
    "                    # get method ko/tko\n",
    "                    method_tag = fight_details.find(\"i\", attrs={\"style\": \"font-style: normal\"})\n",
    "                    method = method_tag.get_text(strip=True) if method_tag else \"-\"\n",
    "\n",
    "                # extract data from table\n",
    "                table_stats = soup.find_all(\"table\", class_=\"b-fight-details__table js-fight-table\")\n",
    "                #print(len(table_stats)) #2\n",
    "                table1= table_stats[0] #top totals table third table\n",
    "                table2= table_stats[1] #significant table body attack forth table\n",
    "\n",
    "                                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b2c04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#req again with new link from matchlinks\n",
    "import re\n",
    "\n",
    "fight_link=[]\n",
    "# define before your for-loop- to save \n",
    "round1_data, round2_data, round3_data = [], [], [] #save same fight that end with same total round in 1 file\n",
    "\n",
    "for match in match_links:\n",
    "    response = requests.get(match)\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "    #in each match link table\n",
    "    #find all right row\n",
    "    fight_rows = soup.find_all('tr', class_=\"b-fight-details__table-row b-fight-details__table-row__hover js-fight-details-click\")\n",
    "\n",
    "    for row in fight_rows:\n",
    "        tds = row.find_all(\"td\") #find all td in each fight row\n",
    "        if len(tds) >= 9: #total row is 9 - 0~9\n",
    "            #get data in each row\n",
    "            #get weight in 6 row. find the p tag with info\n",
    "            weight_class = tds[6].find(\"p\").get_text(strip=True)\n",
    "            #get method in 7 row. have 2 p tag get the first one\n",
    "            method = tds[7].find_all(\"p\")[0].get_text(strip=True)\n",
    "            #get total round in 8 row\n",
    "            total_round = tds[8].find(\"p\").get_text(strip=True) #1,2,3 - total round that ends\n",
    "\n",
    "            #get only matching category\n",
    "            category = weight_class == \"Lightweight\" and (method in [\"KO/TKO\", \"KO\", \"TKO\"])\n",
    "            if category:\n",
    "                #print(\"match found\",weight_class, method)\n",
    "                #get data link to go to the stats table and extract data \n",
    "                data_link = row.get(\"data-link\") # all fight link that matched the category\n",
    "                #print(data_link)\n",
    "\n",
    "                # req again with the fight link to go to stats table\n",
    "                data_link_response = requests.get(data_link)\n",
    "                soup = BeautifulSoup(data_link_response.text, \"html.parser\")\n",
    "\n",
    "                # extract data in stats table page\n",
    "                fight_details = soup.find(\"div\", class_=\"b-fight-details__fight\")\n",
    "                if fight_details:\n",
    "                    # get round num\n",
    "                    total_round = fight_details.find(\"i\", class_=\"b-fight-details__text-item\").get_text(strip=True)\n",
    "                    # get method ko/tko\n",
    "                    method_tag = fight_details.find(\"i\", attrs={\"style\": \"font-style: normal\"})\n",
    "                    method = method_tag.get_text(strip=True) if method_tag else \"-\"\n",
    "\n",
    "                # extract data from table\n",
    "                table_stats = soup.find_all(\"table\", class_=\"b-fight-details__table js-fight-table\")\n",
    "                #print(len(table_stats)) #2\n",
    "                table1= table_stats[0] #top totals table third table\n",
    "                table2= table_stats[1] #significant table body attack forth table\n",
    "                 #extract data for one match from 2 table. \n",
    "                #now need to do this for all match \n",
    "\n",
    "                if table_stats:\n",
    "                    for section in table1.find_all(\"tr\", class_=\"b-fight-details__table-row\"):\n",
    "                        td_stats = section.find_all(\"td\")\n",
    "                        if len(td_stats) >= 10:  # total col is 10\n",
    "                            # get data in each row ex: round 1\n",
    "                            kd = [p.get_text(strip=True) for p in td_stats[1].find_all(\"p\")]\n",
    "                            sig_str = [p.get_text(strip=True) for p in td_stats[2].find_all(\"p\")]\n",
    "                            sig_str_pct = [p.get_text(strip=True) for p in td_stats[3].find_all(\"p\")]\n",
    "                            total_str = [p.get_text(strip=True) for p in td_stats[4].find_all(\"p\")]\n",
    "                            td_attempt = [p.get_text(strip=True) for p in td_stats[5].find_all(\"p\")]\n",
    "                            td_pct = [p.get_text(strip=True) for p in td_stats[6].find_all(\"p\")]\n",
    "                            sub_att = [p.get_text(strip=True) for p in td_stats[7].find_all(\"p\")]\n",
    "                            rev = [p.get_text(strip=True) for p in td_stats[8].find_all(\"p\")]\n",
    "                            ctrl_sec = [p.get_text(strip=True) for p in td_stats[9].find_all(\"p\")]\n",
    "                            # each list above has [fighter1, fighter2]\n",
    "                            \n",
    "                    for section2 in table2.find_all(\"tr\", class_=\"b-fight-details__table-row\"):\n",
    "                        td_stats_2 = section2.find_all(\"td\")\n",
    "                        if len(td_stats_2) >= 8:\n",
    "                            #get body attack data\n",
    "                            head = [p.get_text(strip=True) for p in td_stats_2[3].find_all(\"p\")]\n",
    "                            body = [p.get_text(strip=True) for p in td_stats_2[4].find_all(\"p\")]\n",
    "                            leg = [p.get_text(strip=True) for p in td_stats_2[5].find_all(\"p\")]\n",
    "                            distance = [p.get_text(strip=True) for p in td_stats_2[6].find_all(\"p\")]\n",
    "                            clinch = [p.get_text(strip=True) for p in td_stats_2[7].find_all(\"p\")]\n",
    "                            ground = [p.get_text(strip=True) for p in td_stats_2[8].find_all(\"p\")]\n",
    "\n",
    "                            print(\"KD:\", kd,\n",
    "                                \"Sig.Str (L/A):\", sig_str,\n",
    "                                \"sig_str_pct:\", sig_str_pct,\n",
    "                                \"total_str (L/A):\", total_str,\n",
    "                                \"td (L/A):\", td_attempt,\n",
    "                                \"td_pct:\", td_pct,\n",
    "                                \"sub_att:\", sub_att,\n",
    "                                \"rev:\", rev,\n",
    "                                \"Control(sec):\", ctrl_sec,\n",
    "                                \"head (L/A):\", head,\n",
    "                                \"body (L/A):\", body,\n",
    "                                \"leg (L/A):\", leg,\n",
    "                                \"distance (L/A):\", distance,\n",
    "                                \"clinch (L/A):\", clinch,\n",
    "                                \"ground (L/A):\", ground,\n",
    "                                \"total_round:\", total_round,\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82141d17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KD: ['0', '0'] Sig.Str (L/A): ['12 of 25', '1 of 4'] sig_str_pct: ['48%', '25%'] total_str (L/A): ['15 of 28', '1 of 4'] td (L/A): ['1 of 1', '0 of 0'] td_pct: ['100%', '---'] sub_att: ['0', '0'] rev: ['0', '0'] Control(sec): ['0:50', '0:00'] head (L/A): ['11 of 28', '3 of 11'] body (L/A): ['5 of 8', '1 of 1'] leg (L/A): ['6 of 7', '4 of 4'] distance (L/A): ['6 of 17', '8 of 15'] clinch (L/A): ['0 of 0', '0 of 1'] ground (L/A): ['16 of 26', '0 of 0'] total_round: 3\n",
      "KD: ['0', '0'] Sig.Str (L/A): ['12 of 25', '1 of 4'] sig_str_pct: ['48%', '25%'] total_str (L/A): ['15 of 28', '1 of 4'] td (L/A): ['1 of 1', '0 of 0'] td_pct: ['100%', '---'] sub_att: ['0', '0'] rev: ['0', '0'] Control(sec): ['0:50', '0:00'] head (L/A): ['20 of 38', '3 of 13'] body (L/A): ['5 of 5', '2 of 4'] leg (L/A): ['0 of 0', '2 of 2'] distance (L/A): ['9 of 21', '5 of 17'] clinch (L/A): ['0 of 0', '1 of 1'] ground (L/A): ['16 of 22', '1 of 1'] total_round: 3\n",
      "KD: ['0', '0'] Sig.Str (L/A): ['12 of 25', '1 of 4'] sig_str_pct: ['48%', '25%'] total_str (L/A): ['15 of 28', '1 of 4'] td (L/A): ['1 of 1', '0 of 0'] td_pct: ['100%', '---'] sub_att: ['0', '0'] rev: ['0', '0'] Control(sec): ['0:50', '0:00'] head (L/A): ['9 of 20', '0 of 2'] body (L/A): ['1 of 1', '0 of 1'] leg (L/A): ['2 of 4', '1 of 1'] distance (L/A): ['6 of 14', '1 of 4'] clinch (L/A): ['0 of 0', '0 of 0'] ground (L/A): ['6 of 11', '0 of 0'] total_round: 3\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#extract data for one match from 2 table. \n",
    "#now need to do this for all match \n",
    "\n",
    "if table_stats:\n",
    "    for section in table1.find_all(\"tr\", class_=\"b-fight-details__table-row\"):\n",
    "        td_stats = section.find_all(\"td\")\n",
    "        if len(td_stats) >= 10:  # total col is 10\n",
    "            # get data in each row ex: round 1\n",
    "            kd = [p.get_text(strip=True) for p in td_stats[1].find_all(\"p\")]\n",
    "            sig_str = [p.get_text(strip=True) for p in td_stats[2].find_all(\"p\")]\n",
    "            sig_str_pct = [p.get_text(strip=True) for p in td_stats[3].find_all(\"p\")]\n",
    "            total_str = [p.get_text(strip=True) for p in td_stats[4].find_all(\"p\")]\n",
    "            td_attempt = [p.get_text(strip=True) for p in td_stats[5].find_all(\"p\")]\n",
    "            td_pct = [p.get_text(strip=True) for p in td_stats[6].find_all(\"p\")]\n",
    "            sub_att = [p.get_text(strip=True) for p in td_stats[7].find_all(\"p\")]\n",
    "            rev = [p.get_text(strip=True) for p in td_stats[8].find_all(\"p\")]\n",
    "            ctrl_sec = [p.get_text(strip=True) for p in td_stats[9].find_all(\"p\")]\n",
    "            # each list above has [fighter1, fighter2]\n",
    "            \n",
    "    for section2 in table2.find_all(\"tr\", class_=\"b-fight-details__table-row\"):\n",
    "        td_stats_2 = section2.find_all(\"td\")\n",
    "        if len(td_stats_2) >= 8:\n",
    "             #get body attack data\n",
    "            head = [p.get_text(strip=True) for p in td_stats_2[3].find_all(\"p\")]\n",
    "            body = [p.get_text(strip=True) for p in td_stats_2[4].find_all(\"p\")]\n",
    "            leg = [p.get_text(strip=True) for p in td_stats_2[5].find_all(\"p\")]\n",
    "            distance = [p.get_text(strip=True) for p in td_stats_2[6].find_all(\"p\")]\n",
    "            clinch = [p.get_text(strip=True) for p in td_stats_2[7].find_all(\"p\")]\n",
    "            ground = [p.get_text(strip=True) for p in td_stats_2[8].find_all(\"p\")]\n",
    "\n",
    "            print(\"KD:\", kd,\n",
    "                \"Sig.Str (L/A):\", sig_str,\n",
    "                \"sig_str_pct:\", sig_str_pct,\n",
    "                \"total_str (L/A):\", total_str,\n",
    "                \"td (L/A):\", td_attempt,\n",
    "                \"td_pct:\", td_pct,\n",
    "                \"sub_att:\", sub_att,\n",
    "                \"rev:\", rev,\n",
    "                \"Control(sec):\", ctrl_sec,\n",
    "                \"head (L/A):\", head,\n",
    "                \"body (L/A):\", body,\n",
    "                \"leg (L/A):\", leg,\n",
    "                \"distance (L/A):\", distance,\n",
    "                \"clinch (L/A):\", clinch,\n",
    "                \"ground (L/A):\", ground,\n",
    "                \"total_round:\", total_round,\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d2a736",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ea90be18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ No data to save for round1_1.csv\n",
      "⚠️ No data to save for round2_2.csv\n",
      "⚠️ No data to save for round3_3.csv\n"
     ]
    }
   ],
   "source": [
    "if table_stats:\n",
    "                 # get each round num ex: Round 1, Round 2, Round 3\n",
    "                    #table1 = [th.get_text(strip=True) for th in table_stats.find_all(\"th\", colspan=\"10\")]\n",
    "                    #current_round = None\n",
    "                    for section in table1.find_all(\"thead\", class_=\"b-fight-details__table-row b-fight-details__table-row_type_head\"):\n",
    "                            # check if this row is a round header\n",
    "                            header_th = section.find(\"th\", class_=\"b-fight-details__table-col\")\n",
    "                            if header_th:\n",
    "                                current_round = header_th.get_text(strip=True)  # ex: \"Round 1\"\n",
    "\n",
    "                            # iterate over each fight row\n",
    "                            for r in table1.find_all(\"tr\", class_=\"b-fight-details__table-row\"):\n",
    "                                td_stats = r.find_all(\"td\")\n",
    "                                if len(td_stats) >= 10:  # total col is 10\n",
    "                                    # get data in each row ex: round 1\n",
    "                                    kd = [p.get_text(strip=True) for p in td_stats[1].find_all(\"p\")]\n",
    "                                    sig_str = [p.get_text(strip=True) for p in td_stats[2].find_all(\"p\")]\n",
    "                                    sig_str_pct = [p.get_text(strip=True) for p in td_stats[3].find_all(\"p\")]\n",
    "                                    total_str = [p.get_text(strip=True) for p in td_stats[4].find_all(\"p\")]\n",
    "                                    td_attempt = [p.get_text(strip=True) for p in td_stats[5].find_all(\"p\")]\n",
    "                                    td_pct = [p.get_text(strip=True) for p in td_stats[6].find_all(\"p\")]\n",
    "                                    sub_att = [p.get_text(strip=True) for p in td_stats[7].find_all(\"p\")]\n",
    "                                    rev = [p.get_text(strip=True) for p in td_stats[8].find_all(\"p\")]\n",
    "                                    ctrl_sec = [p.get_text(strip=True) for p in td_stats[9].find_all(\"p\")]\n",
    "                                    # each list above has [fighter1, fighter2]\n",
    "                 \n",
    "                            # APPLY CLEANING\n",
    "                            sig_str = split_of_list(sig_str)\n",
    "                            total_str = split_of_list(total_str)\n",
    "                            td_attempt = split_of_list(td_attempt)\n",
    "                            sig_str_pct = clean_pct_list(sig_str_pct)\n",
    "                            td_pct = clean_pct_list(td_pct)\n",
    "                            sub_att = clean_int_list(sub_att)\n",
    "                            rev = clean_int_list(rev)\n",
    "                            kd = clean_int_list(kd)\n",
    "                            ctrl_sec = ctrl_to_seconds(ctrl_sec)\n",
    "\n",
    "                            #print(\"round:\", current_round,\n",
    "                             #   \"KD:\", kd,\n",
    "                              #  \"Sig.Str (L/A):\", sig_str,\n",
    "                               # \"sig_str_pct:\", sig_str_pct,\n",
    "                                #\"total_str (L/A):\", total_str,\n",
    "                                #\"td (L/A):\", td_attempt,\n",
    "                                #\"td_pct:\", td_pct,\n",
    "                                #\"sub_att:\", sub_att,\n",
    "                                #\"rev:\", rev,\n",
    "                                #\"Control(sec):\", ctrl_sec)\n",
    "\n",
    "\n",
    "                            # iterate over all rows in table\n",
    "                            # get each round num ex: Round 1, Round 2, Round 3                 \n",
    "                            #current_round_2 = None\n",
    "                    for section in table2.find_all(\"thead\", class_=\"b-fight-details__table-row b-fight-details__table-row_type_head\"):\n",
    "                            # check if this row is a round header\n",
    "                            header_th = section.find(\"th\", class_=\"b-fight-details__table-col\")\n",
    "                            if header_th:\n",
    "                                current_round_2 = header_th.get_text(strip=True)  # e.g., \"Round 1\"\n",
    "\n",
    "                            #tbody = section.find_next(\"tbody\") #avoid double loop from header\n",
    "                            #if not tbody:\n",
    "                                #continue\n",
    "\n",
    "                            for rr in table2.find_all(\"tr\", class_=\"b-fight-details__table-row\"):\n",
    "                                td_stats_2 = rr.find_all(\"td\")                    \n",
    "                                if len(td_stats_2) >= 8:\n",
    "                                    #get body attack data\n",
    "                                    head = [p.get_text(strip=True) for p in td_stats_2[3].find_all(\"p\")]\n",
    "                                    body = [p.get_text(strip=True) for p in td_stats_2[4].find_all(\"p\")]\n",
    "                                    leg = [p.get_text(strip=True) for p in td_stats_2[5].find_all(\"p\")]\n",
    "                                    distance = [p.get_text(strip=True) for p in td_stats_2[6].find_all(\"p\")]\n",
    "                                    clinch = [p.get_text(strip=True) for p in td_stats_2[7].find_all(\"p\")]\n",
    "                                    ground = [p.get_text(strip=True) for p in td_stats_2[8].find_all(\"p\")]\n",
    "\n",
    "                                    # each list above has [fighter1, fighter2]\n",
    "                                  # clean \"of\" patterns same as before\n",
    "                            head = split_of_list(head)\n",
    "                            body = split_of_list(body)\n",
    "                            leg = split_of_list(leg)\n",
    "                            distance = split_of_list(distance)\n",
    "                            clinch = split_of_list(clinch)\n",
    "                            ground = split_of_list(ground)\n",
    "\n",
    "                            #print(\"round:\", current_round_2,\n",
    "                               # \"head (L/A):\", head,\n",
    "                               # \"body (L/A):\", body,\n",
    "                               # \"leg (L/A):\", leg,\n",
    "                                #\"distance (L/A):\", distance,\n",
    "                                #\"clinch (L/A):\", clinch,\n",
    "                                #\"ground (L/A):\", ground,\n",
    "                                #\"total_round:\", total_round,\n",
    "                                #\"win method:\", method\n",
    "                                #)\n",
    "                            \n",
    "                            data = {\n",
    "                            \"Round\": current_round_2,\n",
    "                            \"KD\": kd,\n",
    "                            \"Sig_Str\": sig_str,\n",
    "                            \"Sig_Str_%\": sig_str_pct,\n",
    "                            \"Total_Str\": total_str,\n",
    "                            \"Td\": td_attempt,\n",
    "                            \"Td_%\": td_pct,\n",
    "                            \"Sub_Att\": sub_att,\n",
    "                            \"Rev\": rev,\n",
    "                            \"Ctrl(sec)\": ctrl_sec,\n",
    "                            \"Head(L/A)\": head,\n",
    "                            \"Body(L/A)\": body,\n",
    "                            \"Leg(L/A)\": leg,\n",
    "                            \"Distance(L/A)\": distance,\n",
    "                            \"Clinch(L/A)\": clinch,\n",
    "                            \"Ground(L/A)\": ground,\n",
    "                            \"Total_Round\": total_round,\n",
    "                            \"Win_Method\": method\n",
    "                        }\n",
    "\n",
    "                            if total_round == \"Round:1\":\n",
    "                                round1_data.append(data)\n",
    "                            elif total_round == \"Round:2\":\n",
    "                                round2_data.append(data)\n",
    "                            elif total_round == \"Round:3\":\n",
    "                                round3_data.append(data)\n",
    "\n",
    "save_to_csv(\"round1_1.csv\", round1_data)\n",
    "save_to_csv(\"round2_2.csv\", round2_data)\n",
    "save_to_csv(\"round3_3.csv\", round3_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e40071d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Fight 1 saved (KO/TKO, ended Round:1)\n",
      "✅ Fight 2 saved (KO/TKO, ended Round:3)\n",
      "✅ Fight 3 saved (KO/TKO, ended Round:3)\n",
      "✅ Fight 4 saved (KO/TKO, ended Round:2)\n",
      "✅ Fight 5 saved (KO/TKO, ended Round:2)\n",
      "✅ Fight 6 saved (KO/TKO, ended Round:1)\n",
      "✅ Fight 7 saved (KO/TKO, ended Round:1)\n",
      "✅ Fight 8 saved (KO/TKO, ended Round:2)\n",
      "✅ Fight 9 saved (KO/TKO, ended Round:1)\n",
      "✅ Fight 10 saved (KO/TKO, ended Round:2)\n",
      "✅ Fight 11 saved (KO/TKO, ended Round:1)\n",
      "✅ Fight 12 saved (KO/TKO, ended Round:3)\n",
      "✅ Fight 13 saved (KO/TKO, ended Round:1)\n",
      "✅ Fight 14 saved (KO/TKO, ended Round:1)\n",
      "✅ Fight 15 saved (TKO - Doctor's Stoppage, ended Round:1)\n",
      "✅ Fight 16 saved (KO/TKO, ended Round:1)\n",
      "✅ Fight 17 saved (KO/TKO, ended Round:1)\n",
      "✅ Fight 18 saved (KO/TKO, ended Round:2)\n",
      "✅ Fight 19 saved (KO/TKO, ended Round:1)\n",
      "✅ Fight 20 saved (KO/TKO, ended Round:2)\n",
      "✅ Fight 21 saved (TKO - Doctor's Stoppage, ended Round:2)\n",
      "✅ Fight 22 saved (KO/TKO, ended Round:3)\n",
      "✅ Fight 23 saved (KO/TKO, ended Round:1)\n",
      "✅ Fight 24 saved (TKO - Doctor's Stoppage, ended Round:2)\n",
      "✅ Fight 25 saved (KO/TKO, ended Round:3)\n",
      "✅ Fight 26 saved (KO/TKO, ended Round:1)\n",
      "✅ Fight 27 saved (TKO - Doctor's Stoppage, ended Round:3)\n",
      "✅ Fight 28 saved (KO/TKO, ended Round:1)\n",
      "✅ Fight 29 saved (KO/TKO, ended Round:3)\n",
      "✅ Fight 30 saved (KO/TKO, ended Round:1)\n",
      "✅ Fight 31 saved (KO/TKO, ended Round:1)\n",
      "✅ Fight 32 saved (KO/TKO, ended Round:5)\n",
      "✅ Fight 33 saved (KO/TKO, ended Round:2)\n",
      "✅ Fight 34 saved (KO/TKO, ended Round:1)\n",
      "✅ Fight 35 saved (KO/TKO, ended Round:3)\n",
      "✅ Fight 36 saved (KO/TKO, ended Round:2)\n",
      "✅ Fight 37 saved (KO/TKO, ended Round:1)\n",
      "✅ Fight 38 saved (KO/TKO, ended Round:3)\n",
      "✅ Fight 39 saved (KO/TKO, ended Round:1)\n",
      "✅ Fight 40 saved (KO/TKO, ended Round:1)\n",
      "✅ Fight 41 saved (KO/TKO, ended Round:2)\n",
      "✅ Fight 42 saved (KO/TKO, ended Round:1)\n",
      "✅ Fight 43 saved (KO/TKO, ended Round:1)\n",
      "✅ Fight 44 saved (KO/TKO, ended Round:1)\n",
      "✅ Fight 45 saved (KO/TKO, ended Round:1)\n",
      "✅ Fight 46 saved (KO/TKO, ended Round:1)\n",
      "✅ Fight 47 saved (KO/TKO, ended Round:1)\n",
      "✅ Fight 48 saved (KO/TKO, ended Round:3)\n",
      "✅ Fight 49 saved (KO/TKO, ended Round:1)\n",
      "✅ Fight 50 saved (KO/TKO, ended Round:1)\n",
      "✅ Fight 51 saved (KO/TKO, ended Round:1)\n",
      "✅ Fight 52 saved (KO/TKO, ended Round:2)\n",
      "✅ Fight 53 saved (KO/TKO, ended Round:1)\n",
      "✅ Fight 54 saved (KO/TKO, ended Round:2)\n",
      "✅ Fight 55 saved (KO/TKO, ended Round:1)\n",
      "✅ Fight 56 saved (KO/TKO, ended Round:2)\n",
      "✅ Fight 57 saved (KO/TKO, ended Round:1)\n",
      "✅ Fight 58 saved (KO/TKO, ended Round:3)\n",
      "✅ Fight 59 saved (KO/TKO, ended Round:2)\n",
      "✅ Fight 60 saved (KO/TKO, ended Round:3)\n",
      "✅ Fight 61 saved (KO/TKO, ended Round:1)\n",
      "✅ Fight 62 saved (KO/TKO, ended Round:1)\n",
      "✅ Fight 63 saved (KO/TKO, ended Round:1)\n",
      "✅ Fight 64 saved (KO/TKO, ended Round:2)\n",
      "✅ Fight 65 saved (KO/TKO, ended Round:2)\n",
      "✅ Fight 66 saved (KO/TKO, ended Round:2)\n",
      "✅ Fight 67 saved (KO/TKO, ended Round:1)\n",
      "✅ Fight 68 saved (KO/TKO, ended Round:1)\n",
      "✅ Fight 69 saved (KO/TKO, ended Round:1)\n",
      "✅ Fight 70 saved (KO/TKO, ended Round:1)\n",
      "✅ Fight 71 saved (KO/TKO, ended Round:1)\n",
      "✅ Fight 72 saved (TKO - Doctor's Stoppage, ended Round:3)\n",
      "✅ Fight 73 saved (KO/TKO, ended Round:2)\n",
      "✅ Fight 74 saved (KO/TKO, ended Round:2)\n",
      "✅ Fight 75 saved (KO/TKO, ended Round:2)\n",
      "✅ Fight 76 saved (KO/TKO, ended Round:2)\n",
      "✅ Fight 77 saved (KO/TKO, ended Round:1)\n",
      "✅ Fight 78 saved (KO/TKO, ended Round:2)\n",
      "✅ Fight 79 saved (KO/TKO, ended Round:1)\n",
      "✅ Fight 80 saved (KO/TKO, ended Round:2)\n",
      "✅ Fight 81 saved (KO/TKO, ended Round:1)\n",
      "✅ Fight 82 saved (KO/TKO, ended Round:3)\n",
      "✅ Fight 83 saved (KO/TKO, ended Round:5)\n",
      "✅ Fight 84 saved (KO/TKO, ended Round:1)\n",
      "✅ Fight 85 saved (KO/TKO, ended Round:2)\n",
      "✅ Fight 86 saved (KO/TKO, ended Round:1)\n",
      "✅ Fight 87 saved (KO/TKO, ended Round:2)\n",
      "✅ Fight 88 saved (KO/TKO, ended Round:2)\n",
      "✅ Fight 89 saved (KO/TKO, ended Round:2)\n",
      "✅ Fight 90 saved (KO/TKO, ended Round:2)\n",
      "✅ Fight 91 saved (KO/TKO, ended Round:1)\n",
      "✅ Fight 92 saved (KO/TKO, ended Round:2)\n",
      "✅ Fight 93 saved (KO/TKO, ended Round:2)\n",
      "✅ Fight 94 saved (KO/TKO, ended Round:2)\n",
      "✅ Fight 95 saved (KO/TKO, ended Round:1)\n",
      "✅ Fight 96 saved (KO/TKO, ended Round:1)\n",
      "✅ Fight 97 saved (KO/TKO, ended Round:2)\n",
      "✅ Fight 98 saved (KO/TKO, ended Round:3)\n",
      "✅ Fight 99 saved (KO/TKO, ended Round:1)\n",
      "✅ Fight 100 saved (KO/TKO, ended Round:1)\n",
      "✅ Fight 101 saved (KO/TKO, ended Round:1)\n",
      "✅ Fight 102 saved (KO/TKO, ended Round:2)\n",
      "✅ Fight 103 saved (KO/TKO, ended Round:2)\n",
      "✅ Fight 104 saved (KO/TKO, ended Round:1)\n",
      "✅ Fight 105 saved (KO/TKO, ended Round:2)\n",
      "✅ Fight 106 saved (KO/TKO, ended Round:1)\n",
      "✅ Fight 107 saved (KO/TKO, ended Round:3)\n",
      "✅ Fight 108 saved (KO/TKO, ended Round:1)\n",
      "✅ Fight 109 saved (KO/TKO, ended Round:3)\n",
      "✅ Fight 110 saved (TKO - Doctor's Stoppage, ended Round:1)\n",
      "✅ Fight 111 saved (KO/TKO, ended Round:1)\n",
      "✅ Fight 112 saved (KO/TKO, ended Round:1)\n",
      "✅ Fight 113 saved (KO/TKO, ended Round:2)\n",
      "✅ Fight 114 saved (KO/TKO, ended Round:2)\n",
      "✅ Fight 115 saved (KO/TKO, ended Round:2)\n",
      "✅ Fight 116 saved (KO/TKO, ended Round:1)\n",
      "✅ Fight 117 saved (KO/TKO, ended Round:3)\n",
      "✅ Fight 118 saved (KO/TKO, ended Round:1)\n",
      "✅ Fight 119 saved (KO/TKO, ended Round:2)\n",
      "✅ Fight 120 saved (KO/TKO, ended Round:1)\n",
      "✅ Fight 121 saved (KO/TKO, ended Round:1)\n",
      "✅ Fight 122 saved (KO/TKO, ended Round:1)\n",
      "✅ Fight 123 saved (KO/TKO, ended Round:1)\n",
      "✅ Fight 124 saved (KO/TKO, ended Round:1)\n",
      "✅ Fight 125 saved (KO/TKO, ended Round:1)\n",
      "✅ Fight 126 saved (KO/TKO, ended Round:1)\n",
      "✅ Fight 127 saved (KO/TKO, ended Round:1)\n",
      "✅ Fight 128 saved (KO/TKO, ended Round:3)\n",
      "✅ Fight 129 saved (KO/TKO, ended Round:1)\n",
      "✅ Fight 130 saved (TKO - Doctor's Stoppage, ended Round:2)\n",
      "✅ Fight 131 saved (KO/TKO, ended Round:2)\n",
      "✅ Fight 132 saved (KO/TKO, ended Round:5)\n",
      "✅ Fight 133 saved (KO/TKO, ended Round:2)\n",
      "✅ Fight 134 saved (KO/TKO, ended Round:2)\n",
      "✅ Fight 135 saved (KO/TKO, ended Round:1)\n",
      "✅ Fight 136 saved (KO/TKO, ended Round:1)\n",
      "✅ Fight 137 saved (KO/TKO, ended Round:1)\n",
      "✅ Fight 138 saved (KO/TKO, ended Round:1)\n",
      "✅ Fight 139 saved (KO/TKO, ended Round:3)\n",
      "✅ Fight 140 saved (KO/TKO, ended Round:1)\n",
      "✅ Fight 141 saved (KO/TKO, ended Round:1)\n",
      "✅ Fight 142 saved (KO/TKO, ended Round:1)\n",
      "✅ Fight 143 saved (KO/TKO, ended Round:1)\n",
      "✅ Fight 144 saved (KO/TKO, ended Round:2)\n",
      "✅ Fight 145 saved (TKO - Doctor's Stoppage, ended Round:2)\n",
      "✅ Fight 146 saved (KO/TKO, ended Round:1)\n",
      "✅ Fight 147 saved (KO/TKO, ended Round:1)\n",
      "✅ Fight 148 saved (KO/TKO, ended Round:3)\n",
      "✅ Fight 149 saved (TKO - Doctor's Stoppage, ended Round:2)\n",
      "✅ Fight 150 saved (KO/TKO, ended Round:1)\n",
      "✅ Fight 151 saved (KO/TKO, ended Round:2)\n",
      "✅ Fight 152 saved (KO/TKO, ended Round:2)\n",
      "✅ Fight 153 saved (KO/TKO, ended Round:2)\n",
      "✅ Fight 154 saved (KO/TKO, ended Round:1)\n",
      "✅ Fight 155 saved (KO/TKO, ended Round:1)\n",
      "✅ Fight 156 saved (KO/TKO, ended Round:1)\n",
      "✅ Fight 157 saved (KO/TKO, ended Round:2)\n",
      "✅ Fight 158 saved (KO/TKO, ended Round:1)\n",
      "✅ Fight 159 saved (KO/TKO, ended Round:1)\n",
      "✅ Fight 160 saved (KO/TKO, ended Round:2)\n",
      "✅ Fight 161 saved (KO/TKO, ended Round:2)\n",
      "✅ Fight 162 saved (KO/TKO, ended Round:3)\n",
      "✅ Fight 163 saved (KO/TKO, ended Round:3)\n",
      "✅ Fight 164 saved (KO/TKO, ended Round:2)\n",
      "✅ Fight 165 saved (KO/TKO, ended Round:1)\n",
      "✅ Fight 166 saved (KO/TKO, ended Round:2)\n",
      "✅ Fight 167 saved (KO/TKO, ended Round:2)\n",
      "✅ Fight 168 saved (KO/TKO, ended Round:3)\n",
      "✅ Fight 169 saved (KO/TKO, ended Round:2)\n",
      "✅ Fight 170 saved (KO/TKO, ended Round:2)\n",
      "✅ Fight 171 saved (KO/TKO, ended Round:1)\n",
      "✅ Fight 172 saved (KO/TKO, ended Round:2)\n",
      "✅ Fight 173 saved (KO/TKO, ended Round:1)\n",
      "✅ Fight 174 saved (KO/TKO, ended Round:1)\n",
      "✅ Fight 175 saved (TKO - Doctor's Stoppage, ended Round:5)\n",
      "✅ Fight 176 saved (KO/TKO, ended Round:1)\n",
      "✅ Fight 177 saved (KO/TKO, ended Round:4)\n",
      "✅ Fight 178 saved (KO/TKO, ended Round:2)\n",
      "✅ Fight 179 saved (KO/TKO, ended Round:2)\n",
      "✅ Fight 180 saved (KO/TKO, ended Round:1)\n",
      "✅ Fight 181 saved (KO/TKO, ended Round:1)\n",
      "✅ Fight 182 saved (KO/TKO, ended Round:1)\n",
      "✅ Fight 183 saved (KO/TKO, ended Round:1)\n",
      "✅ Fight 184 saved (KO/TKO, ended Round:1)\n",
      "✅ Fight 185 saved (KO/TKO, ended Round:1)\n",
      "✅ Fight 186 saved (KO/TKO, ended Round:3)\n",
      "✅ Fight 187 saved (KO/TKO, ended Round:2)\n",
      "✅ Fight 188 saved (KO/TKO, ended Round:3)\n",
      "✅ Fight 189 saved (KO/TKO, ended Round:1)\n",
      "✅ Fight 190 saved (KO/TKO, ended Round:2)\n",
      "✅ Fight 191 saved (KO/TKO, ended Round:1)\n",
      "✅ Fight 192 saved (KO/TKO, ended Round:2)\n",
      "✅ Fight 193 saved (KO/TKO, ended Round:2)\n",
      "✅ Fight 194 saved (KO/TKO, ended Round:3)\n",
      "✅ Fight 195 saved (KO/TKO, ended Round:1)\n",
      "✅ Fight 196 saved (KO/TKO, ended Round:1)\n",
      "✅ Fight 197 saved (KO/TKO, ended Round:1)\n",
      "✅ Fight 198 saved (KO/TKO, ended Round:1)\n",
      "✅ Fight 199 saved (KO/TKO, ended Round:2)\n",
      "✅ Fight 200 saved (KO/TKO, ended Round:2)\n",
      "✅ Fight 201 saved (KO/TKO, ended Round:1)\n",
      "✅ Fight 202 saved (KO/TKO, ended Round:3)\n",
      "✅ Fight 203 saved (KO/TKO, ended Round:1)\n",
      "✅ Fight 204 saved (KO/TKO, ended Round:1)\n",
      "✅ Fight 205 saved (KO/TKO, ended Round:1)\n",
      "✅ Fight 206 saved (KO/TKO, ended Round:1)\n",
      "✅ Fight 207 saved (KO/TKO, ended Round:2)\n",
      "✅ Fight 208 saved (KO/TKO, ended Round:1)\n",
      "✅ Fight 209 saved (KO/TKO, ended Round:1)\n",
      "✅ Fight 210 saved (KO/TKO, ended Round:2)\n",
      "✅ Fight 211 saved (KO/TKO, ended Round:2)\n",
      "✅ Fight 212 saved (KO/TKO, ended Round:2)\n",
      "✅ Fight 213 saved (KO/TKO, ended Round:2)\n",
      "✅ Fight 214 saved (KO/TKO, ended Round:3)\n",
      "✅ Fight 215 saved (TKO - Doctor's Stoppage, ended Round:3)\n",
      "✅ Fight 216 saved (KO/TKO, ended Round:1)\n",
      "✅ Fight 217 saved (KO/TKO, ended Round:2)\n",
      "✅ Fight 218 saved (KO/TKO, ended Round:1)\n",
      "✅ Fight 219 saved (KO/TKO, ended Round:1)\n",
      "✅ Fight 220 saved (KO/TKO, ended Round:1)\n",
      "✅ Fight 221 saved (KO/TKO, ended Round:2)\n",
      "✅ Fight 222 saved (KO/TKO, ended Round:1)\n",
      "✅ Fight 223 saved (KO/TKO, ended Round:1)\n",
      "✅ Fight 224 saved (KO/TKO, ended Round:1)\n",
      "✅ Fight 225 saved (KO/TKO, ended Round:1)\n",
      "✅ Fight 226 saved (KO/TKO, ended Round:1)\n",
      "✅ Fight 227 saved (KO/TKO, ended Round:1)\n",
      "✅ Fight 228 saved (KO/TKO, ended Round:1)\n",
      "✅ Fight 229 saved (KO/TKO, ended Round:1)\n",
      "✅ Fight 230 saved (KO/TKO, ended Round:3)\n",
      "✅ Fight 231 saved (KO/TKO, ended Round:3)\n",
      "✅ Fight 232 saved (KO/TKO, ended Round:1)\n",
      "✅ Fight 233 saved (KO/TKO, ended Round:1)\n",
      "✅ Fight 234 saved (KO/TKO, ended Round:2)\n",
      "✅ Fight 235 saved (KO/TKO, ended Round:1)\n",
      "✅ Fight 236 saved (KO/TKO, ended Round:1)\n",
      "✅ Fight 237 saved (KO/TKO, ended Round:1)\n",
      "✅ Fight 238 saved (KO/TKO, ended Round:1)\n",
      "✅ Fight 239 saved (TKO - Doctor's Stoppage, ended Round:2)\n",
      "✅ Fight 240 saved (KO/TKO, ended Round:3)\n",
      "✅ Fight 241 saved (KO/TKO, ended Round:1)\n",
      "✅ Fight 242 saved (KO/TKO, ended Round:1)\n",
      "✅ Fight 243 saved (KO/TKO, ended Round:1)\n",
      "✅ Fight 244 saved (KO/TKO, ended Round:1)\n",
      "✅ Fight 245 saved (KO/TKO, ended Round:1)\n",
      "✅ Fight 246 saved (KO/TKO, ended Round:1)\n",
      "✅ Fight 247 saved (KO/TKO, ended Round:2)\n",
      "✅ Fight 248 saved (TKO - Doctor's Stoppage, ended Round:2)\n",
      "✅ Fight 249 saved (KO/TKO, ended Round:1)\n",
      "✅ Fight 250 saved (KO/TKO, ended Round:2)\n",
      "✅ Fight 251 saved (KO/TKO, ended Round:2)\n",
      "✅ Fight 252 saved (KO/TKO, ended Round:1)\n",
      "✅ Fight 253 saved (KO/TKO, ended Round:2)\n",
      "✅ Fight 254 saved (KO/TKO, ended Round:1)\n",
      "✅ Fight 255 saved (KO/TKO, ended Round:2)\n",
      "✅ Fight 256 saved (KO/TKO, ended Round:2)\n",
      "✅ Fight 257 saved (KO/TKO, ended Round:3)\n",
      "✅ Fight 258 saved (KO/TKO, ended Round:2)\n",
      "✅ Saved 135 rows → round1.csv\n",
      "✅ Saved 168 rows → round2.csv\n",
      "✅ Saved 102 rows → round3.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "# === Start main crawl ===\n",
    "\n",
    "round1_data, round2_data, round3_data = [], [], []\n",
    "fight_id = 0\n",
    "\n",
    "for match in match_links:\n",
    "    response = requests.get(match)\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "    fight_rows = soup.find_all(\n",
    "        'tr',\n",
    "        class_=\"b-fight-details__table-row b-fight-details__table-row__hover js-fight-details-click\"\n",
    "    )\n",
    "\n",
    "    for row in fight_rows:\n",
    "        tds = row.find_all(\"td\")\n",
    "        if len(tds) >= 9:\n",
    "            weight_class = tds[6].find(\"p\").get_text(strip=True)\n",
    "            method = tds[7].find_all(\"p\")[0].get_text(strip=True)\n",
    "            total_round = tds[8].find(\"p\").get_text(strip=True)\n",
    "\n",
    "            if weight_class == \"Lightweight\" and method in [\"KO/TKO\", \"KO\", \"TKO\"]:\n",
    "                data_link = row.get(\"data-link\")\n",
    "                data_link_response = requests.get(data_link)\n",
    "                soup = BeautifulSoup(data_link_response.text, \"html.parser\")\n",
    "\n",
    "                fight_details = soup.find(\"div\", class_=\"b-fight-details__fight\")\n",
    "                if fight_details:\n",
    "                    total_round = fight_details.find(\"i\", class_=\"b-fight-details__text-item\").get_text(strip=True)\n",
    "                    method_tag = fight_details.find(\"i\", attrs={\"style\": \"font-style: normal\"})\n",
    "                    method = method_tag.get_text(strip=True) if method_tag else \"-\"\n",
    "\n",
    "                table_stats = soup.find_all(\"table\", class_=\"b-fight-details__table js-fight-table\")\n",
    "                if not table_stats or len(table_stats) < 2:\n",
    "                    continue\n",
    "\n",
    "                table1, table2 = table_stats\n",
    "                round_data = []  # store all rounds for this fight\n",
    "\n",
    "                # Extract headers\n",
    "                headers = table1.find_all(\"th\", class_=\"b-fight-details__table-col\")\n",
    "                round_headers = [th.get_text(strip=True) for th in headers if \"Round\" in th.get_text()]\n",
    "\n",
    "                for current_round in round_headers:\n",
    "                    # Extract table1 (totals)\n",
    "                    for r in table1.find_all(\"tr\", class_=\"b-fight-details__table-row\"):\n",
    "                        td_stats = r.find_all(\"td\")\n",
    "                        if len(td_stats) >= 10:\n",
    "                            kd = [p.get_text(strip=True) for p in td_stats[1].find_all(\"p\")]\n",
    "                            sig_str = [p.get_text(strip=True) for p in td_stats[2].find_all(\"p\")]\n",
    "                            sig_str_pct = [p.get_text(strip=True) for p in td_stats[3].find_all(\"p\")]\n",
    "                            total_str = [p.get_text(strip=True) for p in td_stats[4].find_all(\"p\")]\n",
    "                            td_attempt = [p.get_text(strip=True) for p in td_stats[5].find_all(\"p\")]\n",
    "                            td_pct = [p.get_text(strip=True) for p in td_stats[6].find_all(\"p\")]\n",
    "                            sub_att = [p.get_text(strip=True) for p in td_stats[7].find_all(\"p\")]\n",
    "                            rev = [p.get_text(strip=True) for p in td_stats[8].find_all(\"p\")]\n",
    "                            ctrl_sec = [p.get_text(strip=True) for p in td_stats[9].find_all(\"p\")]\n",
    "\n",
    "                            # Clean with regex\n",
    "                            sig_str = split_of_list(sig_str)\n",
    "                            total_str = split_of_list(total_str)\n",
    "                            td_attempt = split_of_list(td_attempt)\n",
    "                            sig_str_pct = clean_pct_list(sig_str_pct)\n",
    "                            td_pct = clean_pct_list(td_pct)\n",
    "                            sub_att = clean_int_list(sub_att)\n",
    "                            rev = clean_int_list(rev)\n",
    "                            kd = clean_int_list(kd)\n",
    "                            ctrl_sec = ctrl_to_seconds(ctrl_sec)\n",
    "\n",
    "                    # Extract table2 (significant strikes)\n",
    "                    for rr in table2.find_all(\"tr\", class_=\"b-fight-details__table-row\"):\n",
    "                        td_stats_2 = rr.find_all(\"td\")\n",
    "                        if len(td_stats_2) >= 8:\n",
    "                            head = [p.get_text(strip=True) for p in td_stats_2[3].find_all(\"p\")]\n",
    "                            body = [p.get_text(strip=True) for p in td_stats_2[4].find_all(\"p\")]\n",
    "                            leg = [p.get_text(strip=True) for p in td_stats_2[5].find_all(\"p\")]\n",
    "                            distance = [p.get_text(strip=True) for p in td_stats_2[6].find_all(\"p\")]\n",
    "                            clinch = [p.get_text(strip=True) for p in td_stats_2[7].find_all(\"p\")]\n",
    "                            ground = [p.get_text(strip=True) for p in td_stats_2[8].find_all(\"p\")]\n",
    "\n",
    "                            head = split_of_list(head)\n",
    "                            body = split_of_list(body)\n",
    "                            leg = split_of_list(leg)\n",
    "                            distance = split_of_list(distance)\n",
    "                            clinch = split_of_list(clinch)\n",
    "                            ground = split_of_list(ground)\n",
    "\n",
    "                    # Store combined round data\n",
    "                    data = {\n",
    "                        \"Fight_ID\": fight_id,\n",
    "                        \"Round\": current_round,\n",
    "                        \"KD\": kd,\n",
    "                        \"Sig_Str\": sig_str,\n",
    "                        \"Sig_Str_%\": sig_str_pct,\n",
    "                        \"Total_Str\": total_str,\n",
    "                        \"Td\": td_attempt,\n",
    "                        \"Td_%\": td_pct,\n",
    "                        \"Sub_Att\": sub_att,\n",
    "                        \"Rev\": rev,\n",
    "                        \"Ctrl(sec)\": ctrl_sec,\n",
    "                        \"Head(L/A)\": head,\n",
    "                        \"Body(L/A)\": body,\n",
    "                        \"Leg(L/A)\": leg,\n",
    "                        \"Distance(L/A)\": distance,\n",
    "                        \"Clinch(L/A)\": clinch,\n",
    "                        \"Ground(L/A)\": ground,\n",
    "                        \"Total_Round\": total_round,\n",
    "                        \"Win_Method\": method,\n",
    "                    }\n",
    "                    round_data.append(data)\n",
    "\n",
    "                # Append to correct file (based on ending round)\n",
    "                if total_round == \"1\" or \"Round:1\" in total_round:\n",
    "                    round1_data.extend(round_data)\n",
    "                elif total_round == \"2\" or \"Round:2\" in total_round:\n",
    "                    round2_data.extend(round_data)\n",
    "                elif total_round == \"3\" or \"Round:3\" in total_round:\n",
    "                    round3_data.extend(round_data)\n",
    "\n",
    "                fight_id += 1\n",
    "                print(f\"✅ Fight {fight_id} saved ({method}, ended {total_round})\")\n",
    "\n",
    "# Save all\n",
    "save_to_csv(\"round1.csv\", round1_data)\n",
    "save_to_csv(\"round2.csv\", round2_data)\n",
    "save_to_csv(\"round3.csv\", round3_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0743d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#if fight A total round end at 3\n",
    "#extract all round data in that link in the data stat table and\n",
    "#all round mean in fight A's round1,round2,round3.\n",
    "#save it to round3 file\n",
    "\n",
    "#try with one fight first\n",
    "#let say fight\n",
    "#http://www.ufcstats.com/fight-details/7cbfeba85f86d1bf\n",
    "#in here the total round is 3\n",
    "#so in the stats table have data for each round 1,2 and 3\n",
    "# extract the data in each round in table totals for KD\tSig. str.\tSig. str. %\tTotal str.\tTd\tTd %\tSub. att\tRev.\tCtrl and\n",
    "# the data in significant strikes table of Head\tBody\tLeg\tDistance\tClinch\tGround\n",
    "#we dont need the Sig. str\tSig. str. % again since duplicate\n",
    "#save the extract data in round3 file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71d52ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#try use id if keep repeated, coz id is uniques so will nop repeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "011e32b3",
   "metadata": {},
   "outputs": [],
   "source": [
    " #req again with the fight link to go to stats table\n",
    "                data_link_response = requests.get(data_link)\n",
    "                soup = BeautifulSoup(data_link_response.text, \"html.parser\")\n",
    "                \n",
    "                #extract data in stats table page\n",
    "                #get total_round first on top of table\n",
    "                fight_details = soup.find(\"div\", class_=\"b-fight-details__fight\")\n",
    "                if fight_details:\n",
    "                    total_round = fight_details.find(\"i\", class_=\"b-fight-details__text-item\").get_text(strip=True) #get round num\n",
    "                    method = fight_details.find(\"i\", style_=\"font-style: normal\").get_text(strip=True) # get method\n",
    "\n",
    "                #extract data from table\n",
    "                table_stats = soup.find(\"table\", class_=\"b-fight-details__table js-fight-table\")\n",
    "                if table_stats:\n",
    "                    round_num = table_stats.find.all(\"th\", class_=\"b-fight-details__table-col\").get_text(strip=True)#get each round num ex:round1\n",
    "\n",
    "                table_stats_row = soup.find(\"tr\", class_=\"b-fight-details__table-row\")\n",
    "                for r in table_stats_row:\n",
    "                    td_stats = row.find_all(\"td\")\n",
    "                    if len(td_stats)>=9:\n",
    "                        #get data in each row ex: round 1\n",
    "                        #fight_id =  [i++]\n",
    "                        kd = td_stats[1].find(\"p\").get_text(strip=True) #0\n",
    "                        sig_str_landed = td_stats[2].find(\"p\")[1].get_text(strip=True) #22\n",
    "                        sig_str_attempted = td_stats[2].find(\"p\")[2].get_text(strip=True) #41\n",
    "                        sid_str_p = td_stats[3].find(\"p\").get_text(strip=True) #53\n",
    "                        total_str_landed = td_stats[4].find(\"p\")[1].get_text(strip=True) #23\n",
    "                        total_str_attempted = td_stats[4].find(\"p\")[2].get_text(strip=True),#42\n",
    "                        td_landed = td_stats[5].find(\"p\")[1].get_text(strip=True) #1\n",
    "                        td_attempted = td_stats[5].find(\"p\")[2].get_text(strip=True) #1\n",
    "                        td_p = td_stats[6].find(\"p\").get_text(strip=True) #100\n",
    "                        sub_att = td_stats[7].find(\"p\").get_text(strip=True) #0\n",
    "                        rev =  td_stats[8].find(\"p\").get_text(strip=True) #0\n",
    "                        ctrl_sec = td_stats[9].find(\"p\").get_text(strip=True) #24 - convert to second\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
